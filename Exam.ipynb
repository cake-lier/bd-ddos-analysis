{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4468a763-ee2d-4e4a-8eb1-1fd9e6dac8d8",
   "metadata": {},
   "source": [
    "# DDoS dataset analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060d8283-69b8-4a27-921c-bf3052e0daea",
   "metadata": {},
   "source": [
    "L'obiettivo di questo progetto è analizzare un _dataset_ contenente informazioni relative sia ad attacchi DDoS che a normale traffico di rete.\n",
    "Questo viene fatto per poter realizzare un'applicazione capace di distinguere il traffico sospetto da quello legittimo e poter quindi tempestivamente bloccare i tentativi di attacco."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031bc6ff-2d80-4ff3-a487-82dabbb6c93b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T09:34:21.907675Z",
     "iopub.status.busy": "2022-06-17T09:34:21.907419Z"
    },
    "tags": []
   },
   "source": [
    "## Descrizione del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e496dcb9",
   "metadata": {},
   "source": [
    "Il _dataset_ è stato ottenuto da un _paper_ scritto dalla \"University of New South Wales\".\n",
    "Il _paper_ è stato pubblicato su [Science Direct](https://www.sciencedirect.com/science/article/abs/pii/S0167739X18327687) ed è disponibile su [ResearchGate](https://www.researchgate.net/publication/328736466_Towards_the_Development_of_Realistic_Botnet_Dataset_in_the_Internet_of_Things_for_Network_Forensic_Analytics_Bot-IoT_Dataset) in _preprint_.\n",
    "Come è scritto in esso, l'obiettivo del _paper_ era la realizzazione del _dataset_ stesso, rispettando le condizioni di massimo realismo possibile del traffico generato e della configurazione dell'ambiente in cui gli attacchi simulati sono stati svolti.\n",
    "\n",
    "Il _paper_ indica anche il fatto che sono state generate diverse tipologie di attacco, ma quelle di interesse sono state solamente quelle inerenti agli attacchi di tipo \"Distributed Denial of Service\", o \"DDoS\" in breve.\n",
    "[Argus](https://openargus.org/) è stato il _software_  utilizzato per effettuare le catture dei pacchetti. La sua documentazione, nonché i suoi [esempi d'uso](https://openargus.org/using-argus), indicano come sono costruiti i _record_ che l'applicazione salva nel momento nel quale viene fatta una cattura di rete.\n",
    "\n",
    "Ogni _record_ è il risultato di un raggruppamento di più pacchetti che svolgono la stessa funzione all'interno di una specifica connessione, o _flow_.\n",
    "Ad esempio, un _record_ può contenere i pacchetti utilizzati dal protocollo \"TCP\" per effettuare l'_handshake_ con un'altro nodo di rete, il corpo della trasmissione, oppure la chiusura finale.\n",
    "Per questo motivo ogni _record_, oltre a contenere informazioni capaci di identificare sorgente e destinazione della connessione, contengono anche dati derivanti dall'aggregazione dalle informazioni di più pacchetti.\n",
    "Infine, dacché è possibile risalire dai _record_ alle singole connessioni, così come esplicitato nel _paper_ stesso, sono presenti anche informazioni su alcuni parametri nati dall'aggregazionr di _record_ differenti, informazioni che ci aspettiamo siano replicate uguali tra tutti i _record_ coinvolti.\n",
    "\n",
    "Il sito in cui il _dataset_ è stato pubblicato è [questo](https://research.unsw.edu.au/projects/bot-iot-dataset), mentre il _download_ dei file può essere fatto dalla [cartella](https://cloudstor.aarnet.edu.au/plus/s/umT99TnxvbpkkoE?path=%2FLabelling) di un servizio _cloud_ della UNSW.\n",
    "I _file_ che sono stati utilizzati in questo progetto sono quelli denominati \"DDoS_HTTP.csv\", \"DDoS_TCP.csv\" e \"DDoS_UDP.csv\".\n",
    "Purtroppo, non è possibile effettuare il _download_ diretto di questi."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf05e9c-8bdf-4444-a221-fc4a00eebaf0",
   "metadata": {},
   "source": [
    "### Descrizione dei file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09614887-84fa-43db-84a7-a90dab519609",
   "metadata": {},
   "source": [
    "I tre _file_ del _dataset_ che sono stati utilizzati contengono tre diverse sotto-categorie di attacchi, ovvero attacchi che inviano messaggi \"HTTP\", segmenti \"TCP\" e datagrammi \"UDP\".\n",
    "Non siamo interessati a tenere conto di questa distinzione, tanto più che tutti e tre i _file_, essendo stati generati dallo stesso _tool_, possiedono lo stesso formato \"CSV\" e gli stessi campi.\n",
    "\n",
    "I campi presenti in ciascun file sono i seguenti:\n",
    "\n",
    "* \"stime\": la data e l'ora di ricezione del primo pacchetto del _record_\n",
    "* \"flgs\": le _flag_ dello stato della connessione presenti nei pacchetti del _record_\n",
    "* \"proto\": il protocollo di livello di trasporto utilizzato dai pacchetti del _record_\n",
    "* \"saddr\": l'indirizzo IP dell'interfaccia sorgente dei pacchetti del _record_\n",
    "* \"sport\": la porta dell'interfaccia sorgente dei pacchetti del _record_\n",
    "* \"dir\": la direzione del flusso dati, da sorgente a destinazione o bidirezionale\n",
    "* \"daddr\": l'indirizzo IP dell'interfaccia destinazione dei pacchetti del _record_\n",
    "* \"dport\": la porta dell'interfaccia destinazione dei pacchetti del _record_\n",
    "* \"pkts\": il numero di pacchetti aggregati dal _record_\n",
    "* \"bytes\": la somma dei _byte_ dei pacchetti aggregati\n",
    "* \"state\": lo stato della connessione per i pacchetti aggregati dal _record_\n",
    "* \"srcid\": l'identificatore usato dal _tool_ \"Argus\" per identificare la sorgente dati\n",
    "* \"ltime\": la data e l'ora di ricezione dell'ultimo pacchetto del _record_\n",
    "* \"seq\": il numero di sequenza che il _tool_ \"Argus\" ha assegnato al _record_\n",
    "* \"dur\": la durata temporale totale del campionamento associato al _record_ \n",
    "* \"mean\": la durata media dei _record_ aggregati\n",
    "* \"stddev\": la deviazione standard dei _record_ aggregati\n",
    "* \"smac\": l'indirizzo MAC della sorgente dei pacchetti del _record_\n",
    "* \"dmac\": l'indirizzo MAC della destinazione dei pacchetti del _record_\n",
    "* \"sum\": la somma delle durate dei _record_ aggregati\n",
    "* \"min\": il minimo delle durate dei _record_ aggregati\n",
    "* \"max\": il massimo delle durate dei _record_ aggregati\n",
    "* \"soui\": lo \"Organizationally Unique Identifier\" dell'indirizzo MAC della sorgente dei pacchetti del _record_\n",
    "* \"doui\": lo \"Organizationally Unique Identifier\" dell'indirizzo MAC della destinazione dei pacchetti del _record_\n",
    "* \"sco\": il \"Country Code\" associato all'indirizzo IP della sorgente dei pacchetti nel _record_\n",
    "* \"dco\": il \"Country Code\" associato all'indirizzo IP della destinazione dei pacchetti nel _record_\n",
    "* \"spkts\": il numero di pacchetti inviati dalla sorgente alla destinazione in questo _record_\n",
    "* \"dpkts\": il numero di pacchetti inviati dalla destinazione alla sorgente in questo _record_\n",
    "* \"sbytes\": il numero di _byte_ inviati dalla sorgente alla destinazione in questo _record_\n",
    "* \"dbytes\": il numero di _byte_ inviati dalla destinazione alla sorgente in questo _record_\n",
    "* \"rate\": i pacchetti al secondo inviati in questo _record_\n",
    "* \"srate\": i pacchetti al secondo inviati dalla sorgente alla destinazione in questo _record_\n",
    "* \"drate\": i pacchetti al secondo inviati dalla destinazione alla sorgente in questo _record_\n",
    "* \"record\": questa feature non è spiegata all'interno del _paper_ né tantomeno nella documentazione di \"Argus\"\n",
    "* \"attack: se il _record_ è parte di un attacco o meno\n",
    "* \"category\": la categoria dell'attacco\n",
    "* \"subcategory\": la specifica sotto-categoria dell'attacco\n",
    "\n",
    "I campi che abbiamo utilizzato nell'analisi sono stati:\n",
    "\n",
    "* stime\n",
    "* proto\n",
    "* saddr\n",
    "* sport\n",
    "* daddr\n",
    "* dport\n",
    "* ltime\n",
    "* dur\n",
    "* pkts\n",
    "* bytes\n",
    "* rate\n",
    "* attack\n",
    "\n",
    "Inoltre, è stato utilizzato un secondo _dataset_ che contiene le associazioni tra le \"well-known ports\" e la descrizione del servizio corrispondente.\n",
    "I campi presenti in questo _dataset_ sono:\n",
    "\n",
    "* port: la \"well-known port\" associata al servizio\n",
    "* protocol: il protocollo associato al servizio\n",
    "* description: la descrizione del servizio\n",
    "\n",
    "Tutti i campi di questo _dataset_ sono stati utilizzati."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608d3d1a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preparazione dei dati"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23733544",
   "metadata": {},
   "source": [
    "Per effettuare la preparazione dei dati, innanzitutto configuriamo il _kernel_ Spark che utilizzeremo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0bd4f15-fadb-4b4e-acc3-7d69545b82b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T10:41:34.013756Z",
     "iopub.status.busy": "2022-06-26T10:41:34.013531Z",
     "iopub.status.idle": "2022-06-26T10:41:34.407354Z",
     "shell.execute_reply": "2022-06-26T10:41:34.406515Z",
     "shell.execute_reply.started": "2022-06-26T10:41:34.013731Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'executorMemory': '8G', 'numExecutors': 2, 'executorCores': 3, 'conf': {'spark.dynamicAllocation.enabled': 'false'}, 'proxyUser': 'assumed-role_voclabs_user1847188_matteo_castellucci3_studio_unibo_it', 'kind': 'spark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "No active sessions."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure -f\n",
    "{\n",
    "    \"executorMemory\": \"8G\", \n",
    "    \"numExecutors\": 2, \n",
    "    \"executorCores\": 3, \n",
    "    \"conf\": {\n",
    "        \"spark.dynamicAllocation.enabled\": \"false\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e6c9eb",
   "metadata": {},
   "source": [
    "Dopodiché, definiamo i percorsi dei file che utilizzeremo così come sono stati salvati sul servizio \"Amazon S3\" ed avviamo una nuova applicazione Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a0f0c12-591e-41de-a0b6-c76c7c035176",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T10:41:36.828811Z",
     "iopub.status.busy": "2022-06-26T10:41:36.828568Z",
     "iopub.status.idle": "2022-06-26T10:42:09.929451Z",
     "shell.execute_reply": "2022-06-26T10:42:09.928759Z",
     "shell.execute_reply.started": "2022-06-26T10:41:36.828787Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc586773448f4fbc89707b5a1a1d3e8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>0</td><td>application_1656236308433_0002</td><td>spark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-8-181.ec2.internal:20888/proxy/application_1656236308433_0002/\" class=\"emr-proxy-link\" emr-resource=\"j-1PW4PAOWC9ZS2\n",
       "\" application-id=\"application_1656236308433_0002\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-7-62.ec2.internal:8042/node/containerlogs/container_1656236308433_0002_01_000001/livy\" >Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bucketName: String = unibo-bd2122-mcastellucci/project\n",
      "pathTCPDataset: String = s3a://unibo-bd2122-mcastellucci/project/DDoS_TCP.csv\n",
      "pathUDPDataset: String = s3a://unibo-bd2122-mcastellucci/project/DDoS_UDP.csv\n",
      "pathHTTPDataset: String = s3a://unibo-bd2122-mcastellucci/project/DDoS_HTTP.csv\n",
      "pathPortsDataset: String = s3a://unibo-bd2122-mcastellucci/project/ports.csv\n",
      "res7: String = SPARK UI: Enable forwarding of port 20888 and connect to http://localhost:20888/proxy/application_1656236308433_0002/\n"
     ]
    }
   ],
   "source": [
    "//val bucketName = \"unibo-bd2122-nfarabegoli/ddos\"\n",
    "val bucketName = \"unibo-bd2122-mcastellucci/project\"\n",
    "\n",
    "val pathTCPDataset = s\"s3a://$bucketName/DDoS_TCP.csv\"\n",
    "val pathUDPDataset = s\"s3a://$bucketName/DDoS_UDP.csv\"\n",
    "val pathHTTPDataset = s\"s3a://$bucketName/DDoS_HTTP.csv\"\n",
    "//val pathTCPDataset = s\"s3a://$bucketName/DDoS_TCP-sampled.csv\"\n",
    "//val pathUDPDataset = s\"s3a://$bucketName/DDoS_UDP-sampled.csv\"\n",
    "//val pathHTTPDataset = s\"s3a://$bucketName/DDoS_HTTP-sampled.csv\"\n",
    "val pathPortsDataset = s\"s3a://$bucketName/ports.csv\"\n",
    "\n",
    "\"SPARK UI: Enable forwarding of port 20888 and connect to http://localhost:20888/proxy/\" + sc.applicationId + \"/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6306a6ed",
   "metadata": {},
   "source": [
    "A questo punto è possibile costruire l'RDD per intero, in modo tale che contenga i dati di tutti e tre i file che ci interessano.\n",
    "Inoltre, è stato caricato il file contenente il _dataset_ delle \"well-known ports\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9152666-1f46-4590-8465-3bb5413fbc15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T10:42:11.632600Z",
     "iopub.status.busy": "2022-06-26T10:42:11.632356Z",
     "iopub.status.idle": "2022-06-26T10:42:12.975149Z",
     "shell.execute_reply": "2022-06-26T10:42:12.974375Z",
     "shell.execute_reply.started": "2022-06-26T10:42:11.632564Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf3e427cb38c44cf9eb8f9c986ab2a80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: org.apache.spark.rdd.RDD[String] = s3a://unibo-bd2122-mcastellucci/project/DDoS_TCP.csv,s3a://unibo-bd2122-mcastellucci/project/DDoS_UDP.csv,s3a://unibo-bd2122-mcastellucci/project/DDoS_HTTP.csv MapPartitionsRDD[1] at textFile at <console>:31\n",
      "ports: org.apache.spark.rdd.RDD[String] = s3a://unibo-bd2122-mcastellucci/project/ports.csv MapPartitionsRDD[3] at textFile at <console>:27\n"
     ]
    }
   ],
   "source": [
    "val dataset = sc.textFile(s\"$pathTCPDataset,$pathUDPDataset,$pathHTTPDataset\")\n",
    "val ports = sc.textFile(pathPortsDataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde7c25d",
   "metadata": {},
   "source": [
    "A questo punto si tratta di fare _parsing_ dei _record_ del _dataset_.\n",
    "Per effettuarlo correttamente, teniamo conto delle seguenti informazioni sui formati dei valori nelle singole colonne:\n",
    "\n",
    "* stime, ltime: il valore è un _timestamp_ in secondi dall'epoca UNIX, anche se è espresso in formato decimale per poter avere la precisione dei millisecondi\n",
    "* proto: il valore può essere uno tra \"udp\", \"tcp\", \"arp\", \"ipv6-icmp\", \"icmp\", \"igmp\", \"rarp\", ognuno dei quali è associato al corrispondente protocollo, sono però di interesse solamente i _record_ associati ai protocolli TCP e UDP\n",
    "* saddr, dadd: il valore è un indirizzo IP in formato \"dotted decimal notation\", può perciò essere salvato come String\n",
    "* sport, dport: il valore è un intero positivo che può arrivare ad un massimo di 65.536, perciò per poter essere rappresentato in linguaggio scala necessita di essere salvato in un Long\n",
    "* pkts, bytes: il valore è un intero positivo di cui non è noto il massimo, per cui è logico pensare di salvare il valore in un Long\n",
    "* dur, rate: il valore è un numero decimale, perciò per mantenere la precisione massima è stato utilizzato un Double\n",
    "* attack: il valore può essere \"1\" nel caso il _record_ appartenga ad un attacco DDoS, \"0\" in caso contrario\n",
    "\n",
    "Detto questo, sono state implementati il seguente Astract Data Type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbcf5940-297d-434b-9329-84c68f592202",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T10:42:14.008578Z",
     "iopub.status.busy": "2022-06-26T10:42:14.008373Z",
     "iopub.status.idle": "2022-06-26T10:42:16.346205Z",
     "shell.execute_reply": "2022-06-26T10:42:16.345443Z",
     "shell.execute_reply.started": "2022-06-26T10:42:14.008555Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b30fc7b0c054d0a856c30f9c9e52fd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import java.time.format.DateTimeFormatter\n",
      "import java.time.{Instant, LocalDateTime, ZoneId}\n",
      "import scala.util.{Try, Success, Failure}\n",
      "defined class Record\n",
      "defined object Record\n",
      "warning: previously defined class Record is not a companion to object Record.\n",
      "Companions must be defined together; you may wish to use :paste mode for this.\n"
     ]
    }
   ],
   "source": [
    "import java.time.format.DateTimeFormatter\n",
    "import java.time.{ Instant, LocalDateTime, ZoneId }\n",
    "import scala.util.{ Try, Success, Failure }\n",
    "\n",
    "case class Record(\n",
    "    startTime: LocalDateTime,\n",
    "    protocol: String,\n",
    "    sourceAddress: String,\n",
    "    sourcePort: Long,\n",
    "    destinationAddress: String,\n",
    "    destinationPort: Long,\n",
    "    packets: Long,\n",
    "    bytes: Long,\n",
    "    endTime: LocalDateTime,\n",
    "    duration: Double,\n",
    "    rate: Double,\n",
    "    isDDoS: Boolean,\n",
    ")\n",
    "\n",
    "object Record {\n",
    "\n",
    "  def apply(r: Seq[String]): Option[Record] =\n",
    "    (for {\n",
    "      startTime <- Try(\n",
    "        Instant.ofEpochMilli((r.head.toDouble * 1000).toLong).atZone(ZoneId.systemDefault()).toLocalDateTime,\n",
    "      )\n",
    "      protocol <- if (r(2) == \"tcp\" || r(2) == \"udp\") Success(r(2)) else Failure(new IllegalStateException())\n",
    "      sourceAddress = r(3)\n",
    "      sourcePort <- Try(r(4).toLong)\n",
    "      destinationAddress = r(6)\n",
    "      destinationPort <- Try(r(7).toLong)\n",
    "      packets <- Try(r(8).toLong)\n",
    "      bytes <- Try(r(9).toLong)\n",
    "      endTime <- Try(\n",
    "        Instant.ofEpochMilli((r(12).toDouble * 1000).toLong).atZone(ZoneId.systemDefault()).toLocalDateTime,\n",
    "      )\n",
    "      duration <- Try(r(14).toDouble)\n",
    "      rate <- Try(r(30).toDouble)\n",
    "      isDDoS = r(34) == \"1\"\n",
    "    } yield new Record(\n",
    "      startTime,\n",
    "      protocol,\n",
    "      sourceAddress,\n",
    "      sourcePort,\n",
    "      destinationAddress,\n",
    "      destinationPort,\n",
    "      packets,\n",
    "      bytes,\n",
    "      endTime,\n",
    "      duration,\n",
    "      rate,\n",
    "      isDDoS,\n",
    "    )).toOption\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd52b6d1-8273-4935-af95-db47efb65d8d",
   "metadata": {},
   "source": [
    "Per effettuare il _parsing_ del _dataset_ contenente le \"well-known ports\" è stato definito un ADT tenendo conto delle seguenti considerazioni sulle colonne:\n",
    "\n",
    "* port: il valore è un intero positivo che può arrivare ad un massimo di 65.536, perciò per poter essere rappresentato in linguaggio scala necessita di essere salvato in un Long\n",
    "* protocol: il valore può essere \"UDP\" o \"TCP\", per coerenza con l'altro _dataset_ questo valore è stato importato come String in formato _lowercase_\n",
    "* description: per semplicità, è stata salvata come una String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5e5cedb-4255-4491-a348-709b690112b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T10:42:16.347418Z",
     "iopub.status.busy": "2022-06-26T10:42:16.347247Z",
     "iopub.status.idle": "2022-06-26T10:42:17.161643Z",
     "shell.execute_reply": "2022-06-26T10:42:17.160887Z",
     "shell.execute_reply.started": "2022-06-26T10:42:16.347396Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03c8844ac69b46f190d575243a85dd01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defined class PortDescription\n",
      "defined object PortDescription\n",
      "warning: previously defined class PortDescription is not a companion to object PortDescription.\n",
      "Companions must be defined together; you may wish to use :paste mode for this.\n"
     ]
    }
   ],
   "source": [
    "case class PortDescription(\n",
    "  port: Long,\n",
    "  protocol: String,\n",
    "  description: String\n",
    ")\n",
    "\n",
    "object PortDescription {\n",
    "\n",
    "  def apply(r: Seq[String]): Option[PortDescription] = \n",
    "    (for {\n",
    "       port <- Try(r.head.toLong)\n",
    "       protocol <- Try(r(1).toLowerCase)\n",
    "       description = r(2)\n",
    "     } yield new PortDescription(port, protocol, description)\n",
    "    ).toOption\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d3b6cd-a02f-4d02-8594-54529560e7c3",
   "metadata": {},
   "source": [
    "Qui di seguito sono stati fatti degli _import_ di classi comuni a più _query_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f52eaab-2898-4184-8233-0501a3a016a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T10:42:17.163792Z",
     "iopub.status.busy": "2022-06-26T10:42:17.163289Z",
     "iopub.status.idle": "2022-06-26T10:42:17.977874Z",
     "shell.execute_reply": "2022-06-26T10:42:17.977172Z",
     "shell.execute_reply.started": "2022-06-26T10:42:17.163753Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43dae2febf0c4212adae4cc86ff5ab7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import org.apache.spark.{HashPartitioner, SparkContext}\n",
      "import org.apache.spark.storage.StorageLevel\n",
      "import org.apache.spark.rdd.RDD\n",
      "import scala.reflect.ClassTag\n"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.{HashPartitioner, SparkContext}\n",
    "import org.apache.spark.storage.StorageLevel\n",
    "import org.apache.spark.rdd.RDD\n",
    "import scala.reflect.ClassTag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac53ff3",
   "metadata": {},
   "source": [
    "Alla definizione è seguito il parsing vero e proprio, che ha tenuto conto del fatto che i tre _file_, essendo in formato CSV, hanno le virgolette che circondano ogni valore di ogni colonna e sono separati dai punti e virgola.\n",
    "Assieme ai _record_ \"legittimi\", per così dire, saranno presenti anche le intestazioni dei tre _file_.\n",
    "Questo però non ci preoccupa perché sappiamo che il _parser_ eliminerà correttamente quelle righe dall'RDD che caricheremo, non avendo lo stesso formato delle altre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20bb05ff-f850-49fb-a432-c977b86f5ce6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T10:42:17.979129Z",
     "iopub.status.busy": "2022-06-26T10:42:17.978956Z",
     "iopub.status.idle": "2022-06-26T10:42:18.762155Z",
     "shell.execute_reply": "2022-06-26T10:42:18.761372Z",
     "shell.execute_reply.started": "2022-06-26T10:42:17.979107Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a5a1a8ba40449c79b6f14b675e461a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsedRecordDataset: org.apache.spark.rdd.RDD[Record] = MapPartitionsRDD[8] at map at <console>:40\n"
     ]
    }
   ],
   "source": [
    "val parsedRecordDataset = \n",
    "    dataset.\n",
    "        map(_.replace(\"\\\"\", \"\")).\n",
    "        map(_.split(\";\")).\n",
    "        map(Record(_)).\n",
    "        filter(_.isDefined).\n",
    "        map(_.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0c115a-538e-4630-bd6b-d01e695d5027",
   "metadata": {},
   "source": [
    "Effettuiamo il _caching_ del _dataset_ per vedere la sua occupazione in formato non serializzato, a cui facciamo seguire la semplice operazione di conteggio per attivare il meccanismo di _caching_ e sapere anche la dimensione in righe del _dataset_.\n",
    "La quantità di memoria occupata complessiva, tra RAM e disco, è di 10.6GB e il numero di _record_ è di 38532503."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0abf6375-f961-4907-8fba-7206ab407587",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T10:42:19.524100Z",
     "iopub.status.busy": "2022-06-26T10:42:19.523883Z",
     "iopub.status.idle": "2022-06-26T10:45:21.555896Z",
     "shell.execute_reply": "2022-06-26T10:45:21.555152Z",
     "shell.execute_reply.started": "2022-06-26T10:42:19.524075Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "088a24f883674ab489a5e26004c646f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recordDataset: parsedRecordDataset.type = MapPartitionsRDD[8] at map at <console>:40\n",
      "recordDatasetSize: Long = 38532503\n"
     ]
    }
   ],
   "source": [
    "val recordDataset = parsedRecordDataset.persist(StorageLevel.MEMORY_AND_DISK)\n",
    "val recordDatasetSize = recordDataset.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ead705-7aa1-480a-a5c2-8ee5300e1899",
   "metadata": {},
   "source": [
    "Per gli stessi motivi di cui sopra, effettuiamo il _caching_ del _dataset_ delle \"well-known port\", a cui facciamo seguire la semplice operazione di conteggio delle righe.\n",
    "La quantità di memoria occupata è di 8.5MB e il numero di _record_ è di 31178."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0184d72c-feeb-4e61-abf5-717098475c90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T10:45:21.557544Z",
     "iopub.status.busy": "2022-06-26T10:45:21.557296Z",
     "iopub.status.idle": "2022-06-26T10:45:22.855880Z",
     "shell.execute_reply": "2022-06-26T10:45:22.855158Z",
     "shell.execute_reply.started": "2022-06-26T10:45:21.557508Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b1c8010248542e99543932d229e374c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "portsDataset: org.apache.spark.rdd.RDD[PortDescription] = MapPartitionsRDD[13] at map at <console>:40\n",
      "cachedPortsDataset: portsDataset.type = MapPartitionsRDD[13] at map at <console>:40\n",
      "res11: Long = 31178\n"
     ]
    }
   ],
   "source": [
    "val portsDataset = \n",
    "    ports.\n",
    "        map(_.replace(\"\\\"\", \"\")).\n",
    "        map(_.split(\",\")).\n",
    "        map(PortDescription(_)).\n",
    "        filter(_.isDefined).\n",
    "        map(_.get)\n",
    "val cachedPortsDataset = portsDataset.persist(StorageLevel.MEMORY_AND_DISK)\n",
    "cachedPortsDataset.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84ac3b4-584e-4f87-be39-ba62ac59f677",
   "metadata": {},
   "source": [
    "Per quanto riguarda il _dataset_ principale, è stato deciso di mantenerlo \"_cached_\" in memoria con possibilità di _spill-over_ su disco perché tutte le _query_ lo utilizzano.\n",
    "È stato deciso di utilizzare questa forma di _caching_ perché l'aggiunta della serializzazione aggiunge un _overhead_ notevole nei tempi di esecuzione anche delle _query_ più semplici, rendendolo inefficiente.\n",
    "La possibilità di servirsi anche del disco è necessaria date le sue dimensioni troppo elevate per poter essere ospitato interamente in memoria.\n",
    "Per quanto riguarda invece il _dataset_ delle \"well-known port\", si è deciso di rimuoverlo dalla _cache_ dato che sarà utilizzato in una sola _query_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d4cc367-74a4-4441-b7b2-45041c415142",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T10:45:22.857687Z",
     "iopub.status.busy": "2022-06-26T10:45:22.857442Z",
     "iopub.status.idle": "2022-06-26T10:45:23.644723Z",
     "shell.execute_reply": "2022-06-26T10:45:23.643979Z",
     "shell.execute_reply.started": "2022-06-26T10:45:22.857653Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "586f3f4731ab4a46b6fb4fb984e06dd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res12: cachedPortsDataset.type = MapPartitionsRDD[13] at map at <console>:40\n"
     ]
    }
   ],
   "source": [
    "cachedPortsDataset.unpersist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5854d3ed-038e-4f2d-9bb5-dd11abd93e93",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013d6e46-2423-4105-aa1a-7b83b9cb7f0c",
   "metadata": {},
   "source": [
    "### Percentuale dei _record_ associati ad attacchi DDoS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f103adac-357a-40f7-ba04-b23952fa3e22",
   "metadata": {},
   "source": [
    "Con questa query si vuole calcolare la percentuale di _record_ che appartengono ad attacchi DDoS nel _dataset_ e così derivare anche il numero di _record_ che __non__ appartengono ad attacchi DDoS, ma a traffico legittimo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df3422b1-8b67-493f-8e9b-c302adf2dfe1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T11:17:55.406898Z",
     "iopub.status.busy": "2022-06-26T11:17:55.406671Z",
     "iopub.status.idle": "2022-06-26T11:18:10.800340Z",
     "shell.execute_reply": "2022-06-26T11:18:10.799612Z",
     "shell.execute_reply.started": "2022-06-26T11:17:55.406875Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "240733d4fc324217868e936a3bc3b711",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ddosCount: (Int, Int) = (38531238,1265)\n"
     ]
    }
   ],
   "source": [
    "val ddosCount = \n",
    "    recordDataset.\n",
    "        map(r => if (r.isDDoS) (1, 0) else (0, 1)).\n",
    "        reduce{ case((ddosCount1, legitCount1), (ddosCount2, legitCount2)) => (ddosCount1 + ddosCount2, legitCount1 + legitCount2) }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cf014d-425d-49df-8c5e-6d65a3bac9b4",
   "metadata": {},
   "source": [
    "La _query_ prende in input l'intero _dataset_ e produce due Long: il primo è il numero di _record_ appartenenti ad attacchi DDoS, il secondo è il numero di _record_ appartenenti a traffico legittimo.\n",
    "\n",
    "La query ha completato in media con un tempo di 12 secondi prendendo in input 10.6 GB di dati.\n",
    "\n",
    "L'implementazione scelta non fa altro che trasformare ogni _record_ in una coppia di valori, dove il primo rappresenta il conteggio dei _record_ associati ad attacchi e il secondo quelli associati a traffico legittimo.\n",
    "La coppia avrà il valore 1 nella posizione corrispondente a quale tipo di traffico il _record_ stesso appartiene, il valore 0 nell'altra.\n",
    "Dopodiché, viene compiuta un'operazione di _reduce_ che somma i valori nelle corrispondenti posizioni."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a472943-e046-4ec8-9bf4-45d7765558a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T11:18:10.802054Z",
     "iopub.status.busy": "2022-06-26T11:18:10.801608Z",
     "iopub.status.idle": "2022-06-26T11:18:30.195019Z",
     "shell.execute_reply": "2022-06-26T11:18:30.194324Z",
     "shell.execute_reply.started": "2022-06-26T11:18:10.802017Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3737506a035340d79544efcb0a644fd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ddosCount: (Int, Int) = (38531238,1265)\n"
     ]
    }
   ],
   "source": [
    "val ddosCount = \n",
    "    recordDataset.\n",
    "        coalesce(12).\n",
    "        map(r => if (r.isDDoS) (1, 0) else (0, 1)).\n",
    "        reduce{ case((ddosCount1, legitCount1), (ddosCount2, legitCount2)) => (ddosCount1 + ddosCount2, legitCount1 + legitCount2) }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83947728-f038-4244-92e0-541b589b42d2",
   "metadata": {},
   "source": [
    "È stata tentata una variante ottimizzata dove si ridimensionano le partizioni dello RDD riducendo il loro numero.\n",
    "Si è però osservato che il tempo rimane essenzialmente costante, se non direttamente peggiora.\n",
    "Per questo motivo, si è giudicata la _query_ originale già ottimale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c79a6a2-c423-477a-a19d-2406fbb64f4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T11:18:30.196463Z",
     "iopub.status.busy": "2022-06-26T11:18:30.196288Z",
     "iopub.status.idle": "2022-06-26T11:18:30.965796Z",
     "shell.execute_reply": "2022-06-26T11:18:30.965211Z",
     "shell.execute_reply.started": "2022-06-26T11:18:30.196442Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4edfffd17a0847f38ec96678ca502094",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ddosPercentage: Double = 99.99671705728538\n",
      "legitPercentage: Double = 0.0032829427146219906\n"
     ]
    }
   ],
   "source": [
    "val ddosPercentage = ddosCount._1 / recordDatasetSize.toDouble * 100\n",
    "val legitPercentage = ddosCount._2 / recordDatasetSize.toDouble * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72dcbb47-4dc1-4c85-b8d5-fda56b4a6bbe",
   "metadata": {},
   "source": [
    "Quello che è possibile dedurre da questa _query_ è che il _dataset_ contiene quasi esclusivamente _record_ inerenti ad attacchi DDoS, il 99.997%. \n",
    "Per qusto motivo, occorrerà tenere in conto questa differenza di peso tra i due tipi di traffico nelle _query_ successive ad esempio analizzandoli separatamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf36315-da7e-4e28-bbf9-3321d724541e",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div align=\"center\">\n",
    "    <img src=\"images/total_pie.png\" width=\"40%\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6913088-ba91-4434-91ae-6a5e47a081d5",
   "metadata": {},
   "source": [
    "### Percentuale dei protocolli coinvolti negli attacchi DDoS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e392430-eb78-495c-a2f7-1cc5c9382d0f",
   "metadata": {},
   "source": [
    "Con questa query si vuole calcolare la percentuale con cui ciascun protocollo, ovvero \"TCP\" e \"UDP\", compare nei _record_ che appartengono ad attacchi DDoS nel _dataset_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c08f3d0-7ba8-4358-bca9-df48c0df0f7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T11:18:30.967032Z",
     "iopub.status.busy": "2022-06-26T11:18:30.966860Z",
     "iopub.status.idle": "2022-06-26T11:18:46.357716Z",
     "shell.execute_reply": "2022-06-26T11:18:46.357030Z",
     "shell.execute_reply.started": "2022-06-26T11:18:30.967010Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f2842499f3e4bdf8bb7ad45a4633676",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ddosByProtocol: (Int, Int) = (19566842,18964396)\n"
     ]
    }
   ],
   "source": [
    "val ddosByProtocol = \n",
    "    recordDataset.\n",
    "        filter(_.isDDoS).\n",
    "        map(r => if (r.protocol == \"tcp\") (1, 0) else (0, 1)).\n",
    "        reduce{ case((tcpCount1, udpCount1), (tcpCount2, udpCount2)) => (tcpCount1 + tcpCount2, udpCount1 + udpCount2) }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27e4521-f211-4437-8210-bf846b70cd0b",
   "metadata": {
    "tags": []
   },
   "source": [
    "La _query_ prende in input l'intero _dataset_ e produce due Long: il primo è il numero di _record_ il cui protocollo di livello di trasporto è \"TCP\", il secondo è il numero di _record_ il cui protocollo è \"UDP\".\n",
    "\n",
    "La query ha completato in media con un tempo di 13 secondi prendendo in input 10.6 GB di dati.\n",
    "\n",
    "L'implementazione scelta filtra il _dataset_ per eliminare i _record_ che appartengono a traffico legittimo, per poi  trasformare ogni _record_ in una coppia di valori, dove il primo rappresenta il conteggio dei _record_ associati al protocollo \"TCP\" e il secondo quelli associati a quello \"UDP\".\n",
    "La coppia avrà il valore 1 nella posizione corrispondente a quale tipo di protocollo il _record_ stesso è associato, il valore 0 nell'altra.\n",
    "Dopodiché, viene compiuta un'operazione di _reduce_ che somma i valori nelle corrispondenti posizioni."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e65d386-1449-4e8d-8110-7655a9864dc1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T11:18:46.358833Z",
     "iopub.status.busy": "2022-06-26T11:18:46.358625Z",
     "iopub.status.idle": "2022-06-26T11:19:03.685987Z",
     "shell.execute_reply": "2022-06-26T11:19:03.685299Z",
     "shell.execute_reply.started": "2022-06-26T11:18:46.358800Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a43b6744af74acbaa440d3e3724591a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ddosByProtocol: (Int, Int) = (19566842,18964396)\n"
     ]
    }
   ],
   "source": [
    "val ddosByProtocol = \n",
    "    recordDataset.\n",
    "        coalesce(12).\n",
    "        filter(_.isDDoS).\n",
    "        map(r => if (r.protocol == \"tcp\") (1, 0) else (0, 1)).\n",
    "        reduce{ case((tcpCount1, udpCount1), (tcpCount2, udpCount2)) => (tcpCount1 + tcpCount2, udpCount1 + udpCount2) }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc5fdc1-f7c1-45d2-9cdf-a589f7b4a120",
   "metadata": {},
   "source": [
    "È stata tentata una variante ottimizzata dove si ridimensionano le partizioni dello RDD riducendo il loro numero.\n",
    "Si è però osservato che il tempo rimane essenzialmente costante, se non direttamente peggiora.\n",
    "Per questo motivo, si è giudicata la _query_ originale già ottimale.\n",
    "Questo fatto non ci sorprende, dacché la _query_ per come è implementata è molto simile alla precedente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c01c82e6-e151-4164-a663-86daae8dab7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T11:19:03.687248Z",
     "iopub.status.busy": "2022-06-26T11:19:03.687045Z",
     "iopub.status.idle": "2022-06-26T11:19:04.473947Z",
     "shell.execute_reply": "2022-06-26T11:19:04.473325Z",
     "shell.execute_reply.started": "2022-06-26T11:19:03.687225Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "773befb77b504ce68b3249849fa50e5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tcpPercentage: Double = 50.780095962102436\n",
      "udpPercentage: Double = 49.216621095182944\n"
     ]
    }
   ],
   "source": [
    "val tcpPercentage = ddosByProtocol._1 / recordDatasetSize.toDouble * 100\n",
    "val udpPercentage = ddosByProtocol._2 / recordDatasetSize.toDouble * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923ec530-28a9-43df-a30f-55c7c67ecf8a",
   "metadata": {},
   "source": [
    "Come si può notare, il peso che entrambi i protocolli hanno negli attacchi DDoS è all'incirca lo stesso.\n",
    "Non è perciò possibile aspettarsi che un certo segmento sia potenzialmente più o meno pericoloso a seconda del tipo di protocollo di livello di trasporto utilizzato."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f91f25-545b-4c5a-93b0-0f02f363460e",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <img src=\"images/protocol-chart.png\" width=\"40%\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb4441f-8044-405a-ad74-1e6d6b9b41da",
   "metadata": {},
   "source": [
    "### Percentuale dei servizi presi di mira dagli attacchi DDoS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f0b4f6-4b62-4a43-84bf-2e567d2bc21e",
   "metadata": {},
   "source": [
    "Con questa query si vuole calcolare la percentuale con cui ciascun servizio è stato preso di mira dagli attacchi DDoS.\n",
    "Per servizio intendiamo la combinazione di porta e protocollo di livello di trasporto, che di norma sono associati a servizi predefiniti.\n",
    "Ad esempio, il protocollo TCP e la porta 80 sono di norma associati ad un server HTTP, anche se nulla toglie che è possibile che sia presente un altro servizio in ascolto.\n",
    "Certamente, un attaccante può studiare prima il sistema per capire quali servizi sono attivi, ma in mancanza di altre informazioni disponibili ricade su ciò che è vero per default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "396b1984-85a4-43ec-b64e-f92087c654bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T11:19:04.474969Z",
     "iopub.status.busy": "2022-06-26T11:19:04.474795Z",
     "iopub.status.idle": "2022-06-26T11:19:05.249572Z",
     "shell.execute_reply": "2022-06-26T11:19:05.248891Z",
     "shell.execute_reply.started": "2022-06-26T11:19:04.474948Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b7551fb23c0420795210f783969b894",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "servicesDataset: org.apache.spark.rdd.RDD[((Long, String), Int)] = ShuffledRDD[75] at reduceByKey at <console>:36\n"
     ]
    }
   ],
   "source": [
    "val servicesDataset = \n",
    "    recordDataset.\n",
    "        filter(_.isDDoS).\n",
    "        map(r => ((r.destinationPort, r.protocol), 1)).\n",
    "        reduceByKey(_ + _).\n",
    "        persist(StorageLevel.MEMORY_AND_DISK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0f2194b8-1266-46db-8f1e-b3fccdaa9c39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T11:19:05.251418Z",
     "iopub.status.busy": "2022-06-26T11:19:05.251250Z",
     "iopub.status.idle": "2022-06-26T11:19:24.753023Z",
     "shell.execute_reply": "2022-06-26T11:19:24.752098Z",
     "shell.execute_reply.started": "2022-06-26T11:19:05.251397Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7fdf193d85a4e169a359f036af07ab8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "portsCountJoin: Array[((Long, String), (Int, String))] = Array(((80,tcp),(19529331,HTTP)), ((80,udp),(18964396,HTTP)), ((9030,tcp),(4,Tor often used)), ((4116,tcp),(4,Smartcard-TLS)), ((6389,tcp),(4,EMC CLARiiON)), ((53850,tcp),(4,Certificate Management over CMS)), ((53849,tcp),(4,Certificate Management over CMS)), ((53855,tcp),(4,Certificate Management over CMS)), ((50271,tcp),(4,Certificate Management over CMS)), ((6260,tcp),(3,planet M.U.L.E.)), ((6347,tcp),(3,gnutella-rtr)), ((4444,tcp),(3,Xvfb X server virtual frame buffer service)), ((9043,tcp),(3,WebSphere Application Server Administration Console secure)), ((6201,tcp),(3,Thermo-Calc Software AB: Management of service nodes in a processing grid for thermodynamic calculations)), ((2142,tcp),(3,TDMoIP (TDM over IP))), ((6262,tcp),(...\n"
     ]
    }
   ],
   "source": [
    "val portsCountJoin = \n",
    "    servicesDataset.\n",
    "        join(portsDataset.map(d => ((d.port, d.protocol), d.description))).\n",
    "        sortBy(_._2, ascending = false).\n",
    "        collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442f1720-5cca-475a-97b1-2c984f9c7726",
   "metadata": {},
   "source": [
    "La _query_ prende in input sia il _dataset_ principale che quello delle \"well-known ports\" e produce l'elenco dei servizi più colpiti.\n",
    "Ogni riga del risultato è composta da porta e protocollo di trasporto del servizio assieme alla sua descrizione e al conteggio delle occorrenze del servizio nel _dataset_ principale.\n",
    "\n",
    "Non facendo _caching_ dei _dataset_ utilizzati nella _query_, questa ha completato in media con un tempo di 17 secondi prendendo in input 10.6 GB di dati.\n",
    "Utilizzando una strategia di _caching_ per i dati utilizzati prima del _join_, la query completa in circa 1.8 secondi.\n",
    "Da quest'ultimo dato si deriva che l'operazione di _join_ e _sorting_ impiegano circa 2 secondi.\n",
    "\n",
    "L'implementazione scelta filtra il _dataset_ per eliminare i _record_ che appartengono a traffico legittimo, per poi trasformare i _record_ in un formato \"chiave valore\".\n",
    "La chiave è fatta dalla coppia \"porta-protocollo\", mentre il valore è un semplice 1, in modo tale da poter sommare tutti questi valori per chiave e avere così il conteggio delle loro occorrenze.\n",
    "La chiave è poi utile per effettuare l'operazione di _join_ con il _dataset_ contenente le descrizioni dei servizi, permettendoci di ottenere un risultato le cui righe hanno il formato di nostro interesse.\n",
    "L'ultima operazione effettuata è un ordinamento decrescente per poter avere per primi i servizi con maggior numero di occorrenze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "65eec958-4d64-4d02-a7d1-ebce3348683e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T11:19:24.755250Z",
     "iopub.status.busy": "2022-06-26T11:19:24.754908Z",
     "iopub.status.idle": "2022-06-26T11:19:27.068532Z",
     "shell.execute_reply": "2022-06-26T11:19:27.067848Z",
     "shell.execute_reply.started": "2022-06-26T11:19:24.755212Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "473c3102553243b1b0d8ac950dce1d48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "portsBroadcast: org.apache.spark.broadcast.Broadcast[scala.collection.Map[(Long, String),String]] = Broadcast(35)\n",
      "portsCountBroadcast: Array[((Long, String), Int, String)] = Array(((80,tcp),19529331,HTTP), ((80,udp),18964396,HTTP), ((53849,tcp),4,Certificate Management over CMS), ((9030,tcp),4,Tor often used), ((53855,tcp),4,Certificate Management over CMS), ((4116,tcp),4,Smartcard-TLS), ((50271,tcp),4,Certificate Management over CMS), ((53850,tcp),4,Certificate Management over CMS), ((6389,tcp),4,EMC CLARiiON), ((54089,tcp),3,Certificate Management over CMS), ((53852,tcp),3,Certificate Management over CMS), ((54151,tcp),3,Certificate Management over CMS), ((53847,tcp),3,Certificate Management over CMS), ((49774,tcp),3,Certificate Management over CMS), ((54115,tcp),3,Certificate Management over CMS), ((49755,tcp),3,Certificate Management over CMS), ((50270,tcp),3,Certificate Management over CMS), (...\n"
     ]
    }
   ],
   "source": [
    "val portsBroadcast = sc.broadcast(portsDataset.map(d => ((d.port, d.protocol), d.description)).collectAsMap())\n",
    "\n",
    "val portsCountBroadcast = servicesDataset.\n",
    "    map { case (k, count) => portsBroadcast.value.get(k).map(desc => (k, count, desc)) }.\n",
    "    filter(_.isDefined).\n",
    "    map(_.get).\n",
    "    sortBy(_._2, ascending = false).\n",
    "    collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d31557-89bf-440a-929d-f77bdb3e10a2",
   "metadata": {},
   "source": [
    "Una prima tecnica di ottimizzazione prevede l'utilizzo della \"broadcast variable\".\n",
    "In particolare, abbiamo effettuato il _broadcast_ del dataset più piccolo, ovvero quello delle \"well-known ports\".\n",
    "\n",
    "È stato osservato che la query completa in circa 1 secondo, dimezzando il tempo impiegato con la _join_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "357e8cf4-9ee0-4fb2-894f-fd369f4a2f66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T11:19:27.069606Z",
     "iopub.status.busy": "2022-06-26T11:19:27.069437Z",
     "iopub.status.idle": "2022-06-26T11:19:30.101744Z",
     "shell.execute_reply": "2022-06-26T11:19:30.101034Z",
     "shell.execute_reply.started": "2022-06-26T11:19:27.069584Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1ca106ccc1f4f8aa9ca3a6c9c0ade9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "portsCountHashPartition: Array[((Long, String), (Int, String))] = Array(((80,tcp),(19529331,HTTP)), ((80,udp),(18964396,HTTP)), ((9030,tcp),(4,Tor often used)), ((4116,tcp),(4,Smartcard-TLS)), ((6389,tcp),(4,EMC CLARiiON)), ((53849,tcp),(4,Certificate Management over CMS)), ((53850,tcp),(4,Certificate Management over CMS)), ((50271,tcp),(4,Certificate Management over CMS)), ((53855,tcp),(4,Certificate Management over CMS)), ((6260,tcp),(3,planet M.U.L.E.)), ((6347,tcp),(3,gnutella-rtr)), ((4444,tcp),(3,Xvfb X server virtual frame buffer service)), ((9043,tcp),(3,WebSphere Application Server Administration Console secure)), ((6201,tcp),(3,Thermo-Calc Software AB: Management of service nodes in a processing grid for thermodynamic calculations)), ((2142,tcp),(3,TDMoIP (TDM over IP))), ((62...\n"
     ]
    }
   ],
   "source": [
    "val portsCountHashPartition = \n",
    "    servicesDataset.\n",
    "        partitionBy(new HashPartitioner(12)).\n",
    "        join(portsDataset.map(d => ((d.port, d.protocol), d.description))).\n",
    "        sortBy(_._2, ascending = false).\n",
    "        collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa2667e-ee22-4a24-88bc-076b9e1e83c8",
   "metadata": {},
   "source": [
    "Come secondo metodo di ottimizzazione, è stato scelto di ripartizionare il dataset più grande sfruttando un \"hash partitioner\".\n",
    "Sono stati fatti alcuni tentativi per trovare il valore ottimale di partizioni da assegnare all'\"hash partitioner\". Si è giunti alla conclusione che il valore che produce il risultato migliore è 12 partizioni, che corrispondono infatti a 2 macchine ognuna con 3 _core_ e per ogni _core_ 2 partizioni."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "87ae0bde-a876-473e-9723-a23524d6db88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T11:19:30.103356Z",
     "iopub.status.busy": "2022-06-26T11:19:30.103013Z",
     "iopub.status.idle": "2022-06-26T11:19:33.079148Z",
     "shell.execute_reply": "2022-06-26T11:19:33.070325Z",
     "shell.execute_reply.started": "2022-06-26T11:19:30.103318Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f02eb8e42374e46a783ea501fa6584e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "partitioner: org.apache.spark.HashPartitioner = org.apache.spark.HashPartitioner@c\n",
      "portsCountHashPartition: Array[((Long, String), (Int, String))] = Array(((80,tcp),(19529331,HTTP)), ((80,udp),(18964396,HTTP)), ((9030,tcp),(4,Tor often used)), ((4116,tcp),(4,Smartcard-TLS)), ((6389,tcp),(4,EMC CLARiiON)), ((53850,tcp),(4,Certificate Management over CMS)), ((50271,tcp),(4,Certificate Management over CMS)), ((53849,tcp),(4,Certificate Management over CMS)), ((53855,tcp),(4,Certificate Management over CMS)), ((6260,tcp),(3,planet M.U.L.E.)), ((6347,tcp),(3,gnutella-rtr)), ((4444,tcp),(3,Xvfb X server virtual frame buffer service)), ((9043,tcp),(3,WebSphere Application Server Administration Console secure)), ((6201,tcp),(3,Thermo-Calc Software AB: Management of service nodes in a processing grid for thermodynamic calculations)), ((2142,tcp),(3,TDMoIP (TDM over IP))), ((62...\n"
     ]
    }
   ],
   "source": [
    "val partitioner = new HashPartitioner(12)\n",
    "\n",
    "val portsCountHashPartition = \n",
    "    servicesDataset.\n",
    "        partitionBy(partitioner).\n",
    "        join(portsDataset.map(d => ((d.port, d.protocol), d.description)).partitionBy(partitioner)).\n",
    "        sortBy(_._2, ascending = false).\n",
    "        collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79437320-0e1b-44c5-a5e8-0b86374b4857",
   "metadata": {},
   "source": [
    "Partizionare entrambi i dataset con lo stesso _partitioner_ non porta ad alcun vantaggio rispetto a partizionare solo il più grande."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6e928958-b056-4f2f-9a58-016acf2aa338",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T11:19:33.080832Z",
     "iopub.status.busy": "2022-06-26T11:19:33.080549Z",
     "iopub.status.idle": "2022-06-26T11:19:34.383275Z",
     "shell.execute_reply": "2022-06-26T11:19:34.382317Z",
     "shell.execute_reply.started": "2022-06-26T11:19:33.080781Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a08a889f16554622b128e89a2fa23b79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error was encountered:\n",
      "<console>:35: error: not found: value portsCountByJoin\n",
      "       (portsCountByJoin.\n",
      "        ^\n",
      "<console>:38: error: type mismatch;\n",
      " found   : Any\n",
      " required: Int\n",
      "               (s\"$port - $protocol\", f\"$desc%-11s\", f\"$count%-13d\", f\"${(count.toDouble / totalPortsCount * 100).toString.substring(0, 5) + \"%\" }%-10s\")\n",
      "                                                        ^\n",
      "<console>:38: error: value toDouble is not a member of Any\n",
      "               (s\"$port - $protocol\", f\"$desc%-11s\", f\"$count%-13d\", f\"${(count.toDouble / totalPortsCount * 100).toString.substring(0, 5) + \"%\" }%-10s\")\n",
      "                                                                                ^\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val totalPortsCount = portsCountJoin.map(_._2._1).reduce(_ + _)\n",
    "\n",
    "println(\"| Service  | Description | Total records | Percentage |\")\n",
    "println(\"|----------|-------------|---------------|------------|\")\n",
    "(portsCountByJoin.\n",
    "    take(2).\n",
    "    map { case ((port, protocol), (count, desc)) => \n",
    "        (s\"$port - $protocol\", f\"$desc%-11s\", f\"$count%-13d\", f\"${(count.toDouble / totalPortsCount * 100).toString.substring(0, 5) + \"%\" }%-10s\")\n",
    "    }.\n",
    "    toSeq :+ \n",
    "    (\n",
    "        \"Other   \", \n",
    "        \"N/A        \", \n",
    "        f\"${totalPortsCount - portsCountJoin.take(2).map(_._2._1).sum}%-13d\", \n",
    "        f\"${((totalPortsCount - portsCountJoin.take(2).map(_._2._1).sum).toDouble / totalPortsCount * 100).toString.substring(0, 4) + \"%\"}%-10s\")\n",
    "    ).\n",
    "    foreach(t => println(s\"| ${t._1} | ${t._2} | ${t._3} | ${t._4} |\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d778eef0-434a-40dc-8b5e-a13360f50087",
   "metadata": {},
   "source": [
    "Questa query ci ha permesso di capire che il servizio esposto sulla porta 80, un server HTTP, è quello maggiormente attaccato. Per questo motivo, tutto il traffico che arriva a quella specifica porta sarà trattato con maggiore attenzione."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f223021d-1de6-46da-854a-73f54eb9278b",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <img src=\"images/ports-chart.png\" width=\"40%\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434ef8a3-9896-421e-a589-72e24051b86d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Quantità di traffico DDoS in byte rispetto al totale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab8a370-e1ab-4f82-a248-89e71af0fc68",
   "metadata": {},
   "source": [
    "Con questa _query_ si voglioni identificare quali sono gli indirizzi IP che ricevono più traffico legato ad attacchi DDoS, calcolato come numero totale di _bytes_ trasmessi nella connessione. Dopodiché si vuole controntare il traffico DDoS rispetto al traffico totale che quegli indirizzi IP hanno ricevuto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7a9e6d0a-a7da-4140-aa34-7906dce0851a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T11:19:34.384800Z",
     "iopub.status.busy": "2022-06-26T11:19:34.384549Z",
     "iopub.status.idle": "2022-06-26T11:19:51.733051Z",
     "shell.execute_reply": "2022-06-26T11:19:51.732425Z",
     "shell.execute_reply.started": "2022-06-26T11:19:34.384764Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6967c42298d0487ba035a0bbe3c56a84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ddosTrafficByIP: scala.collection.immutable.Map[String,Double] = Map(192.168.100.148 -> 7457.1875, 192.168.100.5 -> 5259153.908203125, 192.168.100.7 -> 3382470.841796875, 192.168.100.3 -> 8999801.200195312, 192.168.100.6 -> 2398495.455078125)\n"
     ]
    }
   ],
   "source": [
    "val ddosTrafficByIP =\n",
    "    recordDataset.\n",
    "    filter(_.isDDoS).\n",
    "    map(r => (r.destinationAddress, r.bytes)).\n",
    "    reduceByKey(_ + _).\n",
    "    map { case (ip, traffic) => (ip, traffic / 1024.0) }.\n",
    "    sortBy(_._2, ascending = false).\n",
    "    take(5).\n",
    "    toMap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a71f16-bcb1-46f9-8710-24d151a27fe8",
   "metadata": {},
   "source": [
    "La _query_ prende in input l'intero _dataset_ e produce in output una mappa che associa ad ogni indirizzo IP la quantità di _bytes_ del traffico DDoS subito.\n",
    "\n",
    "La _query_ prende in input 10.6GB di dati e completa mediamente in 15 secondi.\n",
    "\n",
    "La _query_ trattiene i _record_ che appartengono ad attacchi DDoS e dopodiché trattiene le sole colonne che contengono l'IP della destinazione del traffico e la quantità di _bytes_ ricevuti. Per ogni IP vengono sommati i _bytes_ del traffico ricevuto determinando quello totale per ogni IP. Infine l'unità di misura del traffico viene trasformata in KB e poi quest'ultimo ordinato in senso decrescente. Per una migliore visualizzazione dei risultati vengono presi i primi 5 IP che hanno subito il maggior traffico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "19bc42cf-1967-404d-a6b3-75c421f48e6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-26T11:19:51.734198Z",
     "iopub.status.busy": "2022-06-26T11:19:51.734019Z",
     "iopub.status.idle": "2022-06-26T11:20:01.349315Z",
     "shell.execute_reply": "2022-06-26T11:20:01.347953Z",
     "shell.execute_reply.started": "2022-06-26T11:19:51.734176Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e0d73e063b04d64b8a5c44d25de4daf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34d66a2d5c94441fa685f6591a080d41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-94af27ff822c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'spark'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val totalTrafficByIP =\\n    recordDataset.\\n    map(r => (r.destinationAddress, r.bytes)).\\n    reduceByKey(_ + _).\\n    map { case (ip, traffic) => (ip, traffic / 1024.0) }.\\n    collectAsMap()\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/mnt/notebook-env/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2401\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2402\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2403\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2404\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/notebook-env/lib/python3.7/site-packages/decorator.py\u001b[0m in \u001b[0;36mfun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkwsyntax\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcaller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextras\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m     \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/notebook-env/lib/python3.7/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/notebook-env/lib/python3.7/site-packages/sparkmagic/livyclientlib/exceptions.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_errors_are_fatal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/notebook-env/lib/python3.7/site-packages/sparkmagic/livyclientlib/exceptions.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions_to_handle\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_errors_are_fatal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/notebook-env/lib/python3.7/site-packages/sparkmagic/kernels/kernelmagics.py\u001b[0m in \u001b[0;36mspark\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m    369\u001b[0m             \u001b[0mcoerce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_coerce_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoerce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_spark\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplemethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplefraction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoerce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/notebook-env/lib/python3.7/site-packages/sparkmagic/magics/sparkmagicsbase.py\u001b[0m in \u001b[0;36mexecute_spark\u001b[0;34m(self, cell, output_var, samplemethod, maxrows, samplefraction, session_name, coerce, cell_kind)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexecute_spark\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplemethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplefraction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoerce\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_kind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmimetype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspark_controller\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_kind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown_session_on_spark_statement_errors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/notebook-env/lib/python3.7/site-packages/sparkmagic/livyclientlib/sparkcontroller.py\u001b[0m in \u001b[0;36mrun_command\u001b[0;34m(self, command, client_name)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0msession_to_use\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_session_by_name_or_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcommand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession_to_use\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_sqlquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msqlquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/notebook-env/lib/python3.7/site-packages/sparkmagic/livyclientlib/command.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, session)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhttp_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_statement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mstatement_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mu'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_statement_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             self._spark_events.emit_statement_execution_end_event(session.guid, session.kind, session.id,\n",
      "\u001b[0;32m/mnt/notebook-env/lib/python3.7/site-packages/sparkmagic/livyclientlib/command.py\u001b[0m in \u001b[0;36m_get_statement_output\u001b[0;34m(self, session, statement_id)\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mFINAL_STATEMENT_STATUS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0mprogress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'progress'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                 \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m                 \u001b[0mretries\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/notebook-env/lib/python3.7/site-packages/sparkmagic/livyclientlib/livysession.py\u001b[0m in \u001b[0;36msleep\u001b[0;34m(self, retries)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_policy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseconds_to_sleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;31m# This function will refresh the status and get the logs in a single call.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "val totalTrafficByIP =\n",
    "    recordDataset.\n",
    "    map(r => (r.destinationAddress, r.bytes)).\n",
    "    reduceByKey(_ + _).\n",
    "    map { case (ip, traffic) => (ip, traffic / 1024.0) }.\n",
    "    collectAsMap()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc57871-1344-465c-95c3-c1ead3ce7ec8",
   "metadata": {},
   "source": [
    "La _query_ prende in input l'intero _dataset_ e produce in output una mappa che associa ad ogni indirizzo IP la quantità di _bytes_ del traffico totale ricevuto.\n",
    "\n",
    "La _query_ prende in input 10.6GB di dati e completa mediamente in 15 secondi.\n",
    "\n",
    "La _query_ trattiene le sole colonne che contengono l'IP della destinazione del traffico e la quantità di _bytes_ ricevuti. Per ogni IP vengono sommati i _bytes_ del traffico ricevuto determinando quello totale per ogni IP. Infine l'unità di misura del traffico viene trasformata in KB e poi quest'ultimo ordinato in senso decrescente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fc87b8-bf9e-48ff-92d8-a226216f9cbe",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-26T11:20:01.350074Z",
     "iopub.status.idle": "2022-06-26T11:20:01.350337Z",
     "shell.execute_reply": "2022-06-26T11:20:01.350207Z"
    }
   },
   "outputs": [],
   "source": [
    "val trafficByIPCached =\n",
    "    recordDataset.\n",
    "    map(r => ((r.destinationAddress, r.isDDoS), r.bytes)).\n",
    "    reduceByKey(_ + _).\n",
    "    map { case ((ip, ddos), traffic) => (ip, ddos, traffic / 1024.0) }.\n",
    "    persist(StorageLevel.MEMORY_AND_DISK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dad730-81f9-4ea3-bbf4-d3f3546e9e12",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-26T11:20:01.351378Z",
     "iopub.status.idle": "2022-06-26T11:20:01.351730Z",
     "shell.execute_reply": "2022-06-26T11:20:01.351555Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "val ddosTrafficByIpCache = trafficByIPCached.\n",
    "    filter(_._2).\n",
    "    map(r => (r._1, r._3)).\n",
    "    reduceByKey(_ + _).\n",
    "    sortBy(_._2, ascending = false).\n",
    "    take(5).\n",
    "    toMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2025968a-9b32-4fdd-ba2c-ae419add7718",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-26T11:20:01.352860Z",
     "iopub.status.idle": "2022-06-26T11:20:01.353244Z",
     "shell.execute_reply": "2022-06-26T11:20:01.353039Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "val totalTrafficByIpCache = trafficByIPCached.\n",
    "    map(r => (r._1, r._3)).\n",
    "    reduceByKey(_ + _).\n",
    "    collectAsMap()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b843fa2d-06ec-42e9-8da6-1eac69031ae1",
   "metadata": {},
   "source": [
    "Per ottimizzare questa query, essendo composta da due sotto _query_ le cui operazioni iniziali sono molto simili, è stato deciso di impiegare il meccanismo di _caching_ sulla parte comune delle operazioni. Questo ha implicato riscrivere leggermente entrambe le _query_, aumentando il numero di operazioni che compiono complessivamente ma è stato giustificato dal risparmio di tempo ottenuto. Se infatti la prima _query_ esegue comunque in 15 secondi, la seconda esegue in 0.3 secondi, dimezzando i tempi complessivi di esecuzione.\n",
    "\n",
    "Senza contare il tempo necessario per il _caching_, entrambe le _query_ concludono in 0.8 secondi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42716a5-7ae3-4b7d-acdc-60687404df61",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-26T11:20:01.354390Z",
     "iopub.status.idle": "2022-06-26T11:20:01.354741Z",
     "shell.execute_reply": "2022-06-26T11:20:01.354568Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "val totalImportantTraffic = trafficByIP.filterKeys(ddosTrafficByIP.keySet(_))\n",
    "val totalImportantTrafficSorted = totalImportantTraffic.toSeq.sortBy(_._1)\n",
    "val ddosTrafficSorted = ddosTrafficByIP.toSeq.sortBy(_._1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120c2bfb-0aa6-4f36-9360-c80b68e1d20b",
   "metadata": {},
   "source": [
    "La query ci ha permesso di osservare che gli IP `192.168.100.3`, `192.168.100.6` e `192.168.100.7` sono quelli soggetti al maggior traffico DDoS in relazione al traffico totale, quindi quelli maggiormente attaccati."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7807f4c9-a587-4625-9603-d2469e990b1a",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <img src=\"images/ddos-traffic.png\" width=\"40%\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2c30a7-6f24-41ee-b69a-e49db468bbae",
   "metadata": {},
   "source": [
    "### Calcolo delle distribuzioni delle frequenze di invio di pacchetti e bytes per flusso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad285f34-4fe8-4151-aa8b-f303cdc2a292",
   "metadata": {},
   "source": [
    "In questa _query_ si è voluta calcolare la distribuzione di due parametri non presenti nel dataset che sono: la frequenza media di invio dei pacchetti per un flusso e la frequenza media di invio di bytes per un flusso. Per flusso intendiamo un raggruppamento di record identificati da: IP e porta sorgente, IP e porta destinazione e protocollo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3ce2d2-18b5-488c-86ef-12268c00474b",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-26T11:20:01.355751Z",
     "iopub.status.idle": "2022-06-26T11:20:01.356230Z",
     "shell.execute_reply": "2022-06-26T11:20:01.356040Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "val flowsDataset =\n",
    "    recordDataset.\n",
    "    filter(_.duration > 0.0).\n",
    "    map(r =>\n",
    "      (\n",
    "        (r.sourceAddress, r.sourcePort, r.destinationAddress, r.destinationPort, r.protocol),\n",
    "        (r.isDDoS, r.duration, r.packets, r.bytes),\n",
    "      ),\n",
    "    ).\n",
    "    reduceByKey { case ((isDDoS1, duration1, packets1, bytes1), (isDDoS2, duration2, packets2, bytes2)) =>\n",
    "      (isDDoS1 || isDDoS2, duration1 + duration2, packets1 + packets2, bytes1 + bytes2)\n",
    "    }.\n",
    "    map { case (_, (isDDoS, duration, packets, bytes)) => (isDDoS, packets / duration, bytes / duration) }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f586b7fb-1902-4221-ad6c-c44303c71e81",
   "metadata": {},
   "source": [
    "Entrambe le _query_ hanno una parte iniziale in comune dove vengolo eliminate tutte le righe dove la durata è pari a 0 e dopodiché vengono trasformate in una coppia chiave-valore dove la chiave è costituita dalle colonne che identificano un flusso e il valore è costituito invece dalle colonne che saranno utili successivamente, ovvero: se il record è un DDoS o meno, la durata del record, il numero di pacchetti scambiati e il numero di _byte_ trasferiti. \n",
    "Dopodiché vengono sommate per ciascun flusso i valori delle ultime tre colonne e uniti tramite OR logico i valori della prima colonna, che saranno uguali per ciascun flusso. \n",
    "Infine, vengono trasformati i valori in modo tale da ottenere un dataset composto da tre colonne dove la prima indica se la prima da parte di un attacco DDoS o meno, la seconda è la frequenza media di pacchetti e la terza è la frequenza di _byte_ media.\n",
    "\n",
    "La dimensione di questo _dataset_ intermedio è di 776.4 MB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51ed9e1-e2f2-46b4-8966-3fb95c0a1504",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-26T11:20:01.357282Z",
     "iopub.status.idle": "2022-06-26T11:20:01.357723Z",
     "shell.execute_reply": "2022-06-26T11:20:01.357536Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "val (ddosPacketsRateSum, ddosBytesRateSum, ddosCount, legitPacketsRateSum, legitBytesRateSum, legitCount) =\n",
    "    flowsDataset.\n",
    "    map { case (isDDoS, packetsRate, bytesRate) =>\n",
    "      if (isDDoS) (packetsRate, bytesRate, 1, 0.0, 0.0, 0) else (0.0, 0.0, 0, packetsRate, bytesRate, 1)\n",
    "    }.\n",
    "    reduce { \n",
    "      case(\n",
    "        (ddosPacketsRate1, ddosBytesRate1, ddosCount1, legitPacketsRate1, legitBytesRate1, legitCount1), \n",
    "        (ddosPacketsRate2, ddosBytesRate2, ddosCount2, legitPacketsRate2, legitBytesRate2, legitCount2)\n",
    "      ) => (\n",
    "        ddosPacketsRate1 + ddosPacketsRate2, \n",
    "        ddosBytesRate1 + ddosBytesRate2, \n",
    "        ddosCount1 + ddosCount2, \n",
    "        legitPacketsRate1 + legitPacketsRate2, \n",
    "        legitBytesRate1 + legitBytesRate2,\n",
    "        legitCount1 + legitCount2\n",
    "      )  \n",
    "    }\n",
    "\n",
    "val ddosPacketsRateMean = ddosPacketsRateSum / ddosCount\n",
    "val ddosBytesRateMean = ddosBytesRateSum / ddosCount\n",
    "val legitPacketsRateMean = legitPacketsRateSum / legitCount\n",
    "val legitBytesRateMean = legitBytesRateSum / legitCount"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ea1b02-1d9b-40e3-b155-2be2049d3583",
   "metadata": {},
   "source": [
    "Questa _query_ prende in input il _dataset_ intermedio e ne produce un altro composto di sei colonne: le prime tre sono la frequenza media dei pacchetti per i flussi DDoS, la frequenza media di _byte_ per i flussi DDoS e il numero di flussi DDoS. Le ultime tre colonne rappresentano gli campi ma per il flussi legittimi.\n",
    "\n",
    "Questa _query_ prende in input 10.6 GB di dati e completa mediamente in 26 secondi, escludendo la generazione del _dataset_ intermedio, che impiega 1.7 minuti.\n",
    "\n",
    "Questa _query_ prende il dataset intermedio costruito in precedenza e lo trasforma in un tupla a sei valori dove se il flusso è DDoS i valori della riga saranno copiati nei primi due campi della tupla, il terzo posto a uno e gli ultimi tre posti a zero, viceversa se il flusso è legittimo. Infine viene effettuata una operazione di somma tra tutte le colonne. Questo permette di ottenere le somme e i conteggi per le due variabili di interesse sia per attacchi DDoS che traffico legittimo consentendo quindi di calcolare i valori medi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20d2c49-9aa3-490f-82d6-7ec5039cac07",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-26T11:20:01.358816Z",
     "iopub.status.idle": "2022-06-26T11:20:01.359207Z",
     "shell.execute_reply": "2022-06-26T11:20:01.358993Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "val ddosPacketsRateMeanBroadcast = sc.broadcast(ddosPacketsRateMean)\n",
    "val ddosBytesRateMeanBroadcast = sc.broadcast(ddosBytesRateMean)\n",
    "val legitPacketsRateMeanBroadcast = sc.broadcast(legitPacketsRateMean)\n",
    "val legitBytesRateMeanBroadcast = sc.broadcast(legitBytesRateMean)\n",
    "\n",
    "val (ddosPacketsRateDiff, ddosBytesRateDiff, legitPacketsRateDiff, legitBytesRateDiff) =\n",
    "    flowsDataset.\n",
    "    map { case (isDDoS, packetsRate, bytesRate) =>\n",
    "      if (isDDoS)\n",
    "        (\n",
    "         math.pow(packetsRate - ddosPacketsRateMeanBroadcast.value, 2),\n",
    "         math.pow(bytesRate - ddosBytesRateMeanBroadcast.value, 2),\n",
    "         0.0,\n",
    "         0.0,\n",
    "        )\n",
    "      else\n",
    "        (\n",
    "         0.0,\n",
    "         0.0,\n",
    "         math.pow(packetsRate - legitPacketsRateMeanBroadcast.value, 2),\n",
    "         math.pow(bytesRate - legitBytesRateMeanBroadcast.value, 2),\n",
    "        )\n",
    "    }.\n",
    "    reduce {\n",
    "      case(\n",
    "        (ddosPacketsRateDiff1, ddosBytesRateDiff1, legitPacketsRateDiff1, legitBytesRateDiff1),\n",
    "        (ddosPacketsRateDiff2, ddosBytesRateDiff2, legitPacketsRateDiff2, legitBytesRateDiff2)\n",
    "      ) => (\n",
    "        ddosPacketsRateDiff1 + ddosPacketsRateDiff2,\n",
    "        ddosBytesRateDiff1 + ddosBytesRateDiff2,\n",
    "        legitPacketsRateDiff1 + legitPacketsRateDiff2,\n",
    "        legitBytesRateDiff1 + legitBytesRateDiff2\n",
    "      )\n",
    "    }\n",
    "\n",
    "val ddosPacketsRateStdDev = math.sqrt(ddosPacketsRateDiff / ddosCount)\n",
    "val ddosBytesRateStdDev = math.sqrt(ddosBytesRateDiff / ddosCount)\n",
    "val legitPacketsRateStdDev = math.sqrt(legitPacketsRateDiff / legitCount)\n",
    "val legitBytesRateStdDev = math.sqrt(legitBytesRateDiff / legitCount)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bf7efb-dfe3-49bd-b7b0-8b0bf2505ac5",
   "metadata": {},
   "source": [
    "Questa _query_ prende in input l'intero dataset e produce un dataset composto di quattro colonne: le prime due sono rispettivamente le somme delle differenze al quadrato tra la frequenza di pacchetti in un flusso DDoS e la frequenza dei byte in un flusso DDoS e le loro medie, mentre le seconde due sono gli stessi campi ma per i flussi legittimi.\n",
    "\n",
    "Questa _query_ prende in input 10.6 GB di dati e completa mediamente in 26 secondi, escludendo la generazione del _dataset_ intermedio, che impiega 1.7 minuti.\n",
    "\n",
    "Questa _query_ prende il dataset intermedio costruito in precedenza e lo trasforma in un tupla a quattro valori dove se il flusso è DDoS la differenza al quadrato tra i valori della riga e le loro medie saranno copiati nei primi due campi della tupla, viceversa se il flusso è legittimo. Infine viene effettuata una operazione di somma tra tutte le colonne. Questo permette di ottenere le somme per le due variabili di interesse sia per attacchi DDoS che traffico legittimo consentendo quindi di calcolare le deviazioni standard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b2ad29-f09b-4137-9f54-d8f4cb419c7d",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-26T11:20:01.360290Z",
     "iopub.status.idle": "2022-06-26T11:20:01.360639Z",
     "shell.execute_reply": "2022-06-26T11:20:01.360465Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "val flowsDatasetCached =\n",
    "    recordDataset.\n",
    "    filter(_.duration > 0.0).\n",
    "    map(r =>\n",
    "      (\n",
    "        (r.sourceAddress, r.sourcePort, r.destinationAddress, r.destinationPort, r.protocol),\n",
    "        (r.isDDoS, r.duration, r.packets, r.bytes),\n",
    "      ),\n",
    "    ).\n",
    "    reduceByKey { case ((isDDoS1, duration1, packets1, bytes1), (isDDoS2, duration2, packets2, bytes2)) =>\n",
    "      (isDDoS1 || isDDoS2, duration1 + duration2, packets1 + packets2, bytes1 + bytes2)\n",
    "    }.\n",
    "    map { case (_, (isDDoS, duration, packets, bytes)) => (isDDoS, packets / duration, bytes / duration) }.\n",
    "    cache()\n",
    "\n",
    "val (ddosPacketsRateSum, ddosBytesRateSum, ddosCount, legitPacketsRateSum, legitBytesRateSum, legitCount) =\n",
    "    flowsDatasetCached.\n",
    "    map { case (isDDoS, packetsRate, bytesRate) =>\n",
    "      if (isDDoS) (packetsRate, bytesRate, 1, 0.0, 0.0, 0) else (0.0, 0.0, 0, packetsRate, bytesRate, 1)\n",
    "    }.\n",
    "    reduce { \n",
    "      case(\n",
    "        (ddosPacketsRate1, ddosBytesRate1, ddosCount1, legitPacketsRate1, legitBytesRate1, legitCount1), \n",
    "        (ddosPacketsRate2, ddosBytesRate2, ddosCount2, legitPacketsRate2, legitBytesRate2, legitCount2)\n",
    "      ) => (\n",
    "        ddosPacketsRate1 + ddosPacketsRate2, \n",
    "        ddosBytesRate1 + ddosBytesRate2, \n",
    "        ddosCount1 + ddosCount2, \n",
    "        legitPacketsRate1 + legitPacketsRate2, \n",
    "        legitBytesRate1 + legitBytesRate2,\n",
    "        legitCount1 + legitCount2\n",
    "      )  \n",
    "    }\n",
    "\n",
    "val ddosPacketsRateMeanBroadcast = sc.broadcast(ddosPacketsRateSum / ddosCount)\n",
    "val ddosBytesRateMeanBroadcast = sc.broadcast(ddosBytesRateSum / ddosCount)\n",
    "val legitPacketsRateMeanBroadcast = sc.broadcast(legitPacketsRateSum / legitCount)\n",
    "val legitBytesRateMeanBroadcast = sc.broadcast(legitBytesRateSum / legitCount)\n",
    "\n",
    "val (ddosPacketsRateDiff, ddosBytesRateDiff, legitPacketsRateDiff, legitBytesRateDiff) =\n",
    "    flowsDatasetCached.\n",
    "    map { case (isDDoS, packetsRate, bytesRate) =>\n",
    "      if (isDDoS)\n",
    "        (\n",
    "         math.pow(packetsRate - ddosPacketsRateMeanBroadcast.value, 2),\n",
    "         math.pow(bytesRate - ddosBytesRateMeanBroadcast.value, 2),\n",
    "         0.0,\n",
    "         0.0,\n",
    "        )\n",
    "      else\n",
    "        (\n",
    "         0.0,\n",
    "         0.0,\n",
    "         math.pow(packetsRate - legitPacketsRateMeanBroadcast.value, 2),\n",
    "         math.pow(bytesRate - legitBytesRateMeanBroadcast.value, 2),\n",
    "        )\n",
    "    }.\n",
    "    reduce {\n",
    "      case(\n",
    "        (ddosPacketsRateDiff1, ddosBytesRateDiff1, legitPacketsRateDiff1, legitBytesRateDiff1),\n",
    "        (ddosPacketsRateDiff2, ddosBytesRateDiff2, legitPacketsRateDiff2, legitBytesRateDiff2)\n",
    "      ) => (\n",
    "        ddosPacketsRateDiff1 + ddosPacketsRateDiff2,\n",
    "        ddosBytesRateDiff1 + ddosBytesRateDiff2,\n",
    "        legitPacketsRateDiff1 + legitPacketsRateDiff2,\n",
    "        legitBytesRateDiff1 + legitBytesRateDiff2\n",
    "      )\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be969509-9d3d-47f1-8ea1-b5dd861d9fb9",
   "metadata": {},
   "source": [
    "È stato applicato il meccanismo di _caching_ per cercare di ottimizzare l'esecuzione delle due _sub-query_, suggerito dalla presenza del _dataset_ intermedio che entrambe sfruttano.\n",
    "Benché Spark abbia un meccanismo di _caching_ \"interno\", capace di ottimizzare le _query_ che vengono fatte a partire da variabili che vengono riutilizzate, il _caching_ esplicito del _dataset_ dà risultati comunque superiori.\n",
    "Infatti, utilizzando il _caching_ la prima _query_ impiega solamente 0.3 secondi per eseguire, mentre la prima 0.5 secondi, ignorando il tempo di _caching_ che si aggira attorno agli 1.7 minuti, lo stesso che senza esplicitarlo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c56144-4f72-4b5d-89b1-89df5fdf4a1e",
   "metadata": {},
   "source": [
    "Con i valori calcolati sono state costruite le distribuizioni gaussiane delle frequenze dei pacchetti per flusso e dei byte per flusso, sia per quelli DDoS che quelli legittimi.\n",
    "\n",
    "Si può osservare che il traffico DDoS ha una frequenza di pacchetti relativamente bassa, attorno a 0.27 pacchetti al secondo, mentre invece il traffico legittimo ha una frequenza di pacchetti che si aggira mediamente attorno ai 350 pacchetti al secondo. Essendo la varianza per il traffico leggittimo molto più elevata, ciò indica che c'è maggiore incertezza sul valore che la media rappresenta, poiché il traffico legittimo è ragionevole che sia maggiormente eterogeneo.\n",
    "\n",
    "Discorso analogo si può fare per quanto riguarda la frequenza dei _byte_, che è mediamente di 26 _byte_ al secondo per i flussi DDoS, mentre è mediamente di 57573 _bytes_ al secondo per i flussi legittimi.\n",
    "\n",
    "Abbiamo tenuto conto di queste informazioni per calcolare un valore nella nostra metrica che indica un determinato flusso come DDoS tanto più quanto si avvicina ai valori medi qui trovati perché quelli inerenti al traffico legittimo sono troppo distribuiti per essere considerati significativi. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886b23bb-c752-46a8-affa-c0dce6a7cf98",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <div>\n",
    "        <img src=\"images/ddos-flow-packets-rate.png\" width=\"40%\"/>\n",
    "        <img src=\"images/legit-flow-packets-rate.png\" width=\"40%\"/>\n",
    "    </div>\n",
    "    <div>\n",
    "        <img src=\"images/ddos-flow-bytes-rate.png\" width=\"40%\"/>\n",
    "        <img src=\"images/legit-flow-bytes-rate.png\" width=\"40%\"/>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e472687-0e06-492e-9ec1-05b176fd690c",
   "metadata": {},
   "source": [
    "## Statistiche temporali su attacchi "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541b7ec0-95c7-4a98-a4fa-b7d375342f2c",
   "metadata": {},
   "source": [
    "Questa _query_ si da come obiettivo quello di estrapolare l'arco temporale all'interno del quale sono stati condotti gli attacchi DDoS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc90d00-e1e9-4c11-90f1-1a95574b4f1b",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-26T11:20:01.361596Z",
     "iopub.status.idle": "2022-06-26T11:20:01.361971Z",
     "shell.execute_reply": "2022-06-26T11:20:01.361787Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def minDate(date1: LocalDateTime, date2: LocalDateTime): LocalDateTime = {\n",
    "    if (date1.isBefore(date2)) date1 else date2\n",
    "}\n",
    "\n",
    "def maxDate(date1: LocalDateTime, date2: LocalDateTime): LocalDateTime = {\n",
    "    if (date1.isAfter(date2)) date1 else date2\n",
    "}\n",
    "\n",
    "val minMaxDate = recordDataset.filter(_.isDDoS).map(r => (r.startTime, r.startTime)).reduce {\n",
    "    case ((accMax, accMin), (r1, r2)) => (maxDate(accMax, r1), minDate(accMin, r2))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f780d757-ae07-4003-a550-2e551ca7ce06",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "Questa _query_ prende in input l'intero dataset e restituisce una coppia di valori che rappresentano il _timestamp_ più piccolo di inizio di un attacco e il _timestamp_ più grande di inizio di un attacco.\n",
    "\n",
    "La _query_ prende in input 10.6GB di dati e completa mediamente in 14 secondi.\n",
    "\n",
    "La _query_ trattiene solamente i _record_ che appartengono a un attacco DDoS e trasforma ciascuno di essi in una coppia di valori che rappresentano l'inizio dell'attacco. Infine viene calcolato il valore minimo e massimo di quei due valori attraverso una operazione di _reduce_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5ae35a-05cc-4c2e-b245-272a4bce42cd",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-26T11:20:01.363047Z",
     "iopub.status.idle": "2022-06-26T11:20:01.363438Z",
     "shell.execute_reply": "2022-06-26T11:20:01.363246Z"
    }
   },
   "outputs": [],
   "source": [
    "val minMaxDate = recordDataset.\n",
    "    filter(_.isDDoS).\n",
    "    coalesce(12).\n",
    "    map(r => (r.startTime, r.startTime)).\n",
    "    reduce {\n",
    "        case ((accMax, accMin), (r1, r2)) => (maxDate(accMax, r1), minDate(accMin, r2))\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afac771d-d5c6-47c3-ae6f-9e3c4dd80690",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-24T09:48:07.839479Z",
     "iopub.status.busy": "2022-06-24T09:48:07.839117Z",
     "iopub.status.idle": "2022-06-24T09:48:08.129787Z",
     "shell.execute_reply": "2022-06-24T09:48:08.128778Z",
     "shell.execute_reply.started": "2022-06-24T09:48:07.839441Z"
    }
   },
   "source": [
    "Come ottimizzazione è stato tentata la riduzione del numero di partizioni a 12, ma non c'è stato un miglioramento delle prestazioni. Per questo motivo si è rinunciato ad ulteriori ottimizzazioni vista la semplicità della query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6c2d2d-9751-428f-8495-3f2797c16baf",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-26T11:20:01.364386Z",
     "iopub.status.idle": "2022-06-26T11:20:01.364786Z",
     "shell.execute_reply": "2022-06-26T11:20:01.364606Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "val startTime = minMaxDate._2\n",
    "val endTime = minMaxDate._1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e74b46-83ae-4293-b869-cb738780bbcd",
   "metadata": {},
   "source": [
    "Come si può osservare dai risultati precedenti, la distanza temporale tra il primo e l'ultimo attacco è di circa 2.30h. Da questo risultato è stato derivato il fatto che non è possibile estrapolare ulteriori informazioni utili dai _timestamp_."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dac10ef-f7bd-499b-b73d-bd8f816fd89b",
   "metadata": {},
   "source": [
    "### Quartili e distribuzioni delle colonne \"packets\", \"bytes\", \"rate\" e \"byteRate\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5a50ee-0047-4d8c-8d88-c798a73cb22f",
   "metadata": {
    "tags": []
   },
   "source": [
    "In questa _query_ si sono voluti calcolare i quartili delle colonne del _dataset_ \"packets\", \"bytes\", \"rate\" e di una colonna aggiuntiva, non presente nel _dataset_, \"byteRate\", che rappresenta il numero di _byte_ che sono stati inviati al secondo durante una connessione.\n",
    "I quartili sono stati poi utilizzati per ripulire il _dataset_ dai cosiddetti _outlier_ e poter calcolare media e deviazione standard di ciascuna colonna, ovvero la loro distribuzione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a8c46b-1564-4433-a4dd-c79d44803f7c",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-26T11:20:01.365750Z",
     "iopub.status.idle": "2022-06-26T11:20:01.366098Z",
     "shell.execute_reply": "2022-06-26T11:20:01.365927Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "case class Quartiles[T: Numeric](min: T, firstQuartile: T, secondQuartile: T, thirdQuartile: T, max: T)\n",
    "\n",
    "def getStatistics[T: Numeric: Ordering: ClassTag](dataset: RDD[T], size: Long): Quartiles[T] = {\n",
    "    dataset.\n",
    "        sortBy(v => v).\n",
    "        zipWithIndex().\n",
    "        filter { case (_, index) =>\n",
    "            index == 0 || index == size / 4 || index == size / 2 || index == size * 3 / 4 || index == size - 1\n",
    "        }.\n",
    "        collect().\n",
    "        sortBy(_._2).\n",
    "        map(_._1) match {\n",
    "            case Array(min, first, second, third, max) => Quartiles(min, first, second, third, max)\n",
    "        }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7de8c8-d372-4106-a614-8496869371a9",
   "metadata": {},
   "source": [
    "Questa _query_ prende in input una serie di _dataset_ intermedi, ognuno dei quali ha ricevuto un'operazione di eliminazione delle righe che non appartengono al tipo di traffico di interesse e poi un'operazione di trasformazione che porta il _dataset_ ad avere solamente la colonna di interesse.\n",
    "\n",
    "Tutte le _query_ hanno preso in input 10.6 GB di dati.\n",
    "La prima ha completato in circa 39 secondi.\n",
    "La seconda ha completato in circa 70 secondi. \n",
    "La terza ha completato in circa 41 secondi. \n",
    "La quarta ha completato in circa 71 secondi.\n",
    "La quinta ha completato in circa 86 secondi.\n",
    "La sesta ha completato in circa 67 secondi.\n",
    "La settima ha completato in circa 99 secondi.\n",
    "L'ottava ha completato in circa 67 secondi.\n",
    "Qualora si volessero considerare anche i conteggi, tutti e quattro hanno impiegato circa 15 secondi a completare.\n",
    "\n",
    "La _query_ per l'estrazione dei quartili da una colonna presuppone che il _dataset_ sia formato solamente da una colonna di tipo numerico e che sia già stata calcolata la dimensione del _dataset_.\n",
    "La _query_ si preoccupa di ordinare le righe dalla più piccola alla più grande e di numerarle, dopodiché trattiene solamente quelle in corrispondenza dei quartili, ovvero il valore minimo in prima posizione, il valore ad un quarto del _dataset_, la mediana, il valore a tre quarti del _dataset_ e il massimo in ultima posizione.\n",
    "Una volta fatto li si raccoglie e li si ordina per indice, nel caso in cui fossero stati disordinati, e vengono salvati in un'apposita struttura dati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6195bfb2-0b05-4da2-8f14-7a1931f94851",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-26T11:20:01.366871Z",
     "iopub.status.idle": "2022-06-26T11:20:01.367258Z",
     "shell.execute_reply": "2022-06-26T11:20:01.367036Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "val ddosSize = recordDataset.filter(_.isDDoS).count()\n",
    "val legitSize = recordDataset.filter(!_.isDDoS).count()\n",
    "val filteredDDoSSize = recordDataset.filter(r => r.isDDoS && r.duration > 0.0).count()\n",
    "val filteredLegitSize = recordDataset.filter(r => !r.isDDoS && r.duration > 0.0).count()\n",
    "\n",
    "val packetsDDoS = recordDataset.filter(_.isDDoS).map(_.packets)\n",
    "val packetsLegit = recordDataset.filter(!_.isDDoS).map(_.packets)\n",
    "val bytesDDoS = recordDataset.filter(_.isDDoS).map(_.bytes)\n",
    "val bytesLegit = recordDataset.filter(!_.isDDoS).map(_.bytes)\n",
    "val rateDDoS = recordDataset.filter(_.isDDoS).map(_.rate)\n",
    "val rateLegit = recordDataset.filter(!_.isDDoS).map(_.rate)\n",
    "val bytesRateDDoS = recordDataset.filter(r => r.isDDoS && r.duration > 0.0).map(r => r.bytes / r.duration)\n",
    "val bytesRateLegit = recordDataset.filter(r => !r.isDDoS && r.duration > 0.0).map(r => r.bytes / r.duration)\n",
    "\n",
    "val packetQuartileDDoS = getStatistics(packetsDDoS, ddosSize)\n",
    "val packetQuartileLegit = getStatistics(packetsLegit, legitSize)\n",
    "val bytesQuartileDDoS = getStatistics(bytesDDoS, ddosSize)\n",
    "val bytesQuartileLegit = getStatistics(bytesLegit, legitSize)\n",
    "val rateQuartileDDoS = getStatistics(rateDDoS, ddosSize)\n",
    "val rateQuartileLegit = getStatistics(rateLegit, legitSize)\n",
    "val bytesRateQuartileDDoS = getStatistics(bytesRateDDoS, filteredDDoSSize)\n",
    "val bytesRateQuartileLegit = getStatistics(bytesRateLegit, filteredLegitSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba1bb98-099a-45f1-be91-64da2ff181c7",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-26T11:20:01.368277Z",
     "iopub.status.idle": "2022-06-26T11:20:01.368618Z",
     "shell.execute_reply": "2022-06-26T11:20:01.368447Z"
    }
   },
   "outputs": [],
   "source": [
    "case class Gaussian(mean: Double, stdDev: Double)\n",
    "\n",
    "def getGaussian[T: Numeric](sc: SparkContext, rdd: RDD[T]): Gaussian = {\n",
    "    val (sum, count) = rdd.map(r => (r, 1)).reduce{ case((sum1, count1), (sum2, count2)) => (sum1 + sum2, count1 + count2) }\n",
    "    val mean = sum.toDouble() / count\n",
    "    val meanBroadcast = sc.broadcast(mean)\n",
    "\n",
    "    val stdDev = math.sqrt(rdd.map(r => math.pow(r.toDouble() - meanBroadcast.value, 2)).sum() / count)\n",
    "    Gaussian(mean, stdDev)\n",
    "}\n",
    "\n",
    "def cleanByIQR[T: Numeric: Ordering](sc: SparkContext, rdd: RDD[T], quartiles: Quartiles[T]): RDD[T] = {\n",
    "    val rangeBroadcast = sc.broadcast(\n",
    "        (\n",
    "            quartiles.firstQuartile.toDouble() - 1.5 * (quartiles.thirdQuartile - quartiles.firstQuartile).toDouble(),\n",
    "            quartiles.thirdQuartile.toDouble() + 1.5 * (quartiles.thirdQuartile - quartiles.firstQuartile).toDouble(),\n",
    "        ),\n",
    "    )\n",
    "    rdd.filter(r => r.toDouble() > rangeBroadcast.value._1 && r.toDouble() < rangeBroadcast.value._2)\n",
    "}\n",
    "\n",
    "val packetDDoSGaussian = getGaussian(sc, cleanByIQR(sc, packetsDDoS, packetQuartileDDoS))\n",
    "val packetLegitGaussian = getGaussian(sc, cleanByIQR(sc, packetsLegit, packetQuartileLegit))\n",
    "val bytesDDoSGaussian = getGaussian(sc, cleanByIQR(sc, bytesDDoS, bytesQuartileDDoS))\n",
    "val bytesLegitGaussian = getGaussian(sc, cleanByIQR(sc, bytesLegit, bytesQuartileLegit))\n",
    "val rateDDoSGaussian = getGaussian(sc, cleanByIQR(sc, rateDDoS, rateQuartileDDoS))\n",
    "val rateLegitGaussian = getGaussian(sc, cleanByIQR(sc, rateLegit, rateQuartileLegit))\n",
    "val bytesRateDDoSGaussian = getGaussian(sc, cleanByIQR(sc, bytesRateDDoS, bytesRateQuartileDDoS))\n",
    "val bytesRateLegitGaussian = getGaussian(sc, cleanByIQR(sc, bytesRateLegit, bytesRateQuartileLegit))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdff304d-b43f-4e5f-a405-36544d1b9d74",
   "metadata": {},
   "source": [
    "Questa _query_ prende in input una serie di _dataset_ intermedi, ognuno dei quali ha ricevuto un'operazione di eliminazione delle righe che non appartengono al tipo di traffico di interesse e poi un'operazione di trasformazione che porta il _dataset_ ad avere solamente la colonna di interesse.\n",
    "\n",
    "Tutte le _query_ hanno preso in input 10.6 GB di dati.\n",
    "La prima ha completato in circa 31 secondi.\n",
    "La seconda ha completato in circa 26 secondi. \n",
    "La terza ha completato in circa 28 secondi. \n",
    "La quarta ha completato in circa 26 secondi.\n",
    "La quinta ha completato in circa 28 secondi.\n",
    "La sesta ha completato in circa 26 secondi.\n",
    "La settima ha completato in circa 29 secondi.\n",
    "L'ottava ha completato in circa 26 secondi.\n",
    "\n",
    "La _query_ per ottenere la distribuzione gaussiana di ciascuna delle colonne è composta da due fasi.\n",
    "\n",
    "La prima fase si preoccupa dell'eliminazione degli _outlier_ che andrebbero ad inficiare il calcolo dei valori della distribuzione.\n",
    "Questa viene fatta sulla base dei quartili estratti in precedenza, calcolando per ogni valore il _range_ interquartile secondo la sua definizione.\n",
    "Una volta calcolato questo, la _query_ prende in input il _dataset_ precedente ed applica una trasformazione per eliminare tutte quelle righe che non rientrano nel _range_.\n",
    "\n",
    "La seconda fase effettua in prima istanza il calcolo della media, trasformando ogni riga del _dataset_ ripulito in una coppia fatta dal valore originale in essa contenuto e il valore 1 e poi effettuando la somma di tutti i valori in queste due colonne.\n",
    "In questo modo si ottiene la somma dei valori e il loro conteggio e così, dividendoli tra loro, è possibile ottenere il valor medio.\n",
    "A questo punto, per ottenere la deviazione standard, non si fa altro che prendere il _dataset_ ricevuto e trasformare il valore di ciascuna riga nel quadrato della differenza con la media e poi sommare tutti i valori.\n",
    "Dividendo questo valore ottenuto per il numero complessivo di righe nel _dataset_ ottenuto in precedenza e poi calcolando la radice quadrata di quest'ultima si ottiene quindi la deviazione standard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066d6d32-6d59-45cb-b637-8746d24f0799",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-26T11:20:01.369621Z",
     "iopub.status.idle": "2022-06-26T11:20:01.369988Z",
     "shell.execute_reply": "2022-06-26T11:20:01.369808Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "val ddosDataset = recordDataset.filter(_.isDDoS).persist(StorageLevel.MEMORY_AND_DISK)\n",
    "val legitDataset = recordDataset.filter(!_.isDDoS).persist(StorageLevel.MEMORY_AND_DISK)\n",
    "\n",
    "val packetsDDoSCached = ddosDataset.map(_.packets).persist(StorageLevel.MEMORY_AND_DISK)\n",
    "val packetsLegitCached = legitDataset.map(_.packets).persist(StorageLevel.MEMORY_AND_DISK)\n",
    "val bytesDDoSCached = ddosDataset.map(_.bytes).persist(StorageLevel.MEMORY_AND_DISK)\n",
    "val bytesLegitCached = legitDataset.map(_.bytes).persist(StorageLevel.MEMORY_AND_DISK)\n",
    "val rateDDoSCached = ddosDataset.map(_.rate).persist(StorageLevel.MEMORY_AND_DISK)\n",
    "val rateLegitCached = legitDataset.map(_.rate).persist(StorageLevel.MEMORY_AND_DISK)\n",
    "val bytesRateDDoSCached = ddosDataset.filter(_.duration > 0.0).map(r => r.bytes / r.duration).persist(StorageLevel.MEMORY_AND_DISK)\n",
    "val bytesRateLegitCached = legitDataset.filter(_.duration > 0.0).map(r => r.bytes / r.duration).persist(StorageLevel.MEMORY_AND_DISK)\n",
    "\n",
    "val packetQuartileDDoSCached = getStatistics(packetsDDoSCached, ddosSize)\n",
    "val packetQuartileLegitCached = getStatistics(packetsLegitCached, legitSize)\n",
    "val bytesQuartileDDoSCached = getStatistics(bytesDDoSCached, ddosSize)\n",
    "val bytesQuartileLegitCachedCached = getStatistics(bytesLegitCached, legitSize)\n",
    "val rateQuartileDDoSCached = getStatistics(rateDDoSCached, ddosSize)\n",
    "val rateQuartileLegitCached = getStatistics(rateLegitCached, legitSize)\n",
    "val bytesRateQuartileDDoSCached = getStatistics(bytesRateDDoSCached, recordDataset.filter(r => r.isDDoS && r.duration > 0.0).count())\n",
    "val bytesRateQuartileLegitCached = getStatistics(bytesRateLegitCached, recordDataset.filter(r => !r.isDDoS && r.duration > 0.0).count())\n",
    "\n",
    "val packetDDoSGaussianCached = getGaussian(sc, cleanByIQR(sc, packetsDDoSCached, packetQuartileDDoS))\n",
    "val packetLegitGaussianCached = getGaussian(sc, cleanByIQR(sc, packetsLegitCached, packetQuartileLegit))\n",
    "val bytesDDoSGaussianCached = getGaussian(sc, cleanByIQR(sc, bytesDDoSCached, bytesQuartileDDoS))\n",
    "val bytesLegitGaussianCached = getGaussian(sc, cleanByIQR(sc, bytesLegitCached, bytesQuartileLegit))\n",
    "val rateDDoSGaussianCached = getGaussian(sc, cleanByIQR(sc, rateDDoSCached, rateQuartileDDoS))\n",
    "val rateLegitGaussianCached = getGaussian(sc, cleanByIQR(sc, rateLegitCached, rateQuartileLegit))\n",
    "val bytesRateDDoSGaussianCached = getGaussian(sc, cleanByIQR(sc, bytesRateDDoSCached, bytesRateQuartileDDoS))\n",
    "val bytesRateLegitGaussianCached = getGaussian(sc, cleanByIQR(sc, bytesRateLegitCached, bytesRateQuartileLegit))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fb968c-1689-4b54-8160-d05b590c703e",
   "metadata": {},
   "source": [
    "Per ottimizzare l'esecuzione della _query_ è stato deciso di effettuare il _caching_ di tutti _dataset_ intermedi che sono stati utilizzati.\n",
    "\n",
    "In questo modo, per quanto riguarda le _query_ sui quartili, la prima ha completato in 11 secondi, 132 considerando anche le scritture dovute al _caching_.\n",
    "La seconda ha completato in 0.6 secondi, 39 considerando anche le scritture dovute al _caching_.\n",
    "La terza ha completato in 15 secondi, 75 considerando anche le scritture dovute al _caching_.\n",
    "La quarta ha completato in circa 0.9 secondi, indipendentemente dalle scritture dovute al _caching_.\n",
    "La quinta ha completato in 16 secondi, 65 considerando anche le scritture dovute al _caching_.\n",
    "La sesta ha completato in circa 0.9 secondi, indipendentemente dalle scritture dovute al _caching_.\n",
    "La settima ha completato in 17 secondi, 81 considerando anche le scritture dovute al _caching_.\n",
    "L'ottava ha completato in 0.7 secondi, indipendentemente dalle scritture dovute al _caching_.\n",
    "\n",
    "Il vero guadagno si vede però nelle _query_ per il calcolo delle distribuzioni.\n",
    "Infatti, la prima _query_ ha impiegato 3 secondi per completare.\n",
    "La seconda ha impiegato 0.5 secondi per completare.\n",
    "La terza ha impiegato 4 secondi per completare.\n",
    "La quarta ha impiegato 0.2 secondi per completare.\n",
    "La quinta ha impiegato 4 secondi per completare.\n",
    "La sesta ha impiegato 0.3 secondi per completare.\n",
    "La settima ha impiegato 4 secondi per completare.\n",
    "L'ottava ha impiegato 0.4 secondi per completare."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5e1f5a-9800-4570-bac2-7a5d27844e97",
   "metadata": {},
   "source": [
    "Come è possibile osservare per tutti e quattro i campi, i _record_ associati ad attacchi DDoS hanno una distribuzione più \"compatta\" rispetto ai corrispettivi associati a traffico legittimo, cioè con una varianza più bassa, che ci garantisce una maggiore affidabilità del dato.\n",
    "Questo perché, ancora una volta, il traffico legittimo risulta molto variegato e perciò difficile da descrivere con precisione.\n",
    "Inoltre, il valore di ciascun campo per il traffico DDoS è più basso di quello che riguarda quello legittimo.\n",
    "Il numero di pacchetti per _record_ in un attacco DDoS è circa 5.9 pacchetti contro i 1226 per quello legittimo, il numero di _byte_ è di 530 contro 904257, il numero di pacchetti al secondo è di 0.27 contro 61 e infine il numero di byte al secondo è di 34 contro 52217.\n",
    "Utilizzeremo questi valori nella metrica per identificare potenziali flussi di traffico DDoS, sapendo la loro conformazione."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3d4abf-c3b1-410e-91f8-d45f6f164d30",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <div>\n",
    "        <img src=\"images/packets-ddos.png\" width=\"40%\"/>\n",
    "        <img src=\"images/packets-legit.png\" width=\"40%\"/>\n",
    "    </div>\n",
    "    <div>\n",
    "        <img src=\"images/bytes-ddos.png\" width=\"40%\"/>\n",
    "        <img src=\"images/bytes-legit.png\" width=\"40%\"/>\n",
    "    </div>\n",
    "    <div>\n",
    "        <img src=\"images/rates-ddos.png\" width=\"40%\"/>\n",
    "        <img src=\"images/rates-legit.png\" width=\"40%\"/>\n",
    "    </div>\n",
    "    <div>\n",
    "        <img src=\"images/bytesRate-ddos.png\" width=\"40%\"/>\n",
    "        <img src=\"images/bytesRate-legit.png\" width=\"40%\"/>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176e7ab6-d13e-47f6-a895-f7fa74b23141",
   "metadata": {},
   "source": [
    "## Costruzione della metrica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5bad41-8800-4476-aa0e-7a3869c113ec",
   "metadata": {},
   "source": [
    "La metrica è stata costruita sulla base delle analisi svolte in precedenza, assumendo che l'applicazione che dovrà svolgere le analisi riceverà in input _record_ nello stesso formato di quelli del _dataset_ analizzato.\n",
    "Ricapitolando, le informazioni di cui si è tenuto conto sono:\n",
    "\n",
    "* la porta 80 è fortemente soggetta ad attacchi di tipo DDoS\n",
    "* le macchine associate agli indirizzi IP `192.168.100.3`, `192.168.100.6` e `192.168.100.7` sono fortemente soggette ad attacchi di tipo DDoS\n",
    "* le distribuzioni dei campi \"packets\", \"bytes\", \"rate\" e \"byteRate\"\n",
    "* le distribuzioni dei campi \"rate\" e \"byteRate\" per ciascun flusso\n",
    "\n",
    "Queste hanno permesso di costruire la seguente funzione capace di assegnare un peso a ciascun _record_ in arrivo.\n",
    "È bene tenere a mente che la metrica dovrà restituire un valore tra 0 e 1, che potrà essere interpretato come la probabilità che lo specifico _record_ appartenga a traffico DDoS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2f8574-d62e-45a2-9dcb-d3437c98a059",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-26T11:20:01.371189Z",
     "iopub.status.idle": "2022-06-26T11:20:01.371653Z",
     "shell.execute_reply": "2022-06-26T11:20:01.371468Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def metric(\n",
    "    destinationPort: Long, \n",
    "    destinationAddress: String, \n",
    "    packets: Long, \n",
    "    bytes: Long, \n",
    "    rate: Double, \n",
    "    byteRate: Double, \n",
    "    flowRate: Double, \n",
    "    flowByteRate: Double\n",
    "): Double =\n",
    "    ((if (destinationPort == 80L) 1 else 0) +\n",
    "     (if (Set(\"192.168.100.3\", \"192.168.100.6\", \"192.168.100.7\")(destinationAddress)) 1 else 0) +\n",
    "     (1 - math.min(math.abs(packets - 5.909105626202674) / (3 * 3.2784993361685184), 1.0)) +\n",
    "     (1 - math.min(math.abs(bytes - 529.8851801659653) / (3 * 240.0539442965255), 1.0)) +\n",
    "     (1 - math.min(math.abs(rate - 0.27486262284753876) / (3 * 0.18712897621757338), 1.0)) + \n",
    "     (1 - math.min(math.abs(byteRate - 33.86546680087338) / (3 * 17.010164888097375), 1.0)) +\n",
    "     (1 - math.min(math.abs(flowRate - 0.27403419840566284) / (3 * 0.15597820418003489), 1.0)) +\n",
    "     (1 - math.min(math.abs(flowByteRate - 26.483191236399332) / (3 * 14.608112880857705), 1.0))\n",
    "    ) / 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed7bcd3-2d55-4a20-a5d0-18c3ba30fdc7",
   "metadata": {},
   "source": [
    "La metrica si basa su due operazioni fondamentali che permettono di trasformare i suoi parametri in pesi, ovvero in valori compresi tra 0 e 1.\n",
    "La prima si preoccupa di trasformare le grandezze booleane in pesi semplicemente assegnando il peso 1 quando il valore è `true` e 0 quando è `false`.\n",
    "\n",
    "La seconda, più complessa, coinvolge le grandezze numeriche e si basa sul fatto di avere a disposizione la distribuzione delle stesse, assumendo che la forma di queste sia gaussiana.\n",
    "L'idea è quella di ottenere il peso attraverso un'operazione analoga a quella di standardizzazione, che sottrae al valore della misura il valore medio della distribuzione e lo divide per la deviazione standard.\n",
    "Questo viene fatto perchè i valori su cui ci si è basati per la costruzione della gaussiana vengano trasformati in quelli appartenenti ad una distribuzione standard, cioè con media 0 e deviazione standard 1, cosicché tutti i valori che ricadono nel _range_ \\[μ - σ, μ + σ\\] vengono mappati nel _range_ \\[0, 1\\].\n",
    "L'operazione costruita effettua questa operazione di standardizzazione, ma dividendo per tre volte la deviazione standard, in modo tale da far ricadere nel _range_ \\[0, 1\\] il 99,73% dei valori che seguono la distribuzione, evitando la \"saturazione\" di una maggiore quantità di valori.\n",
    "Questa procedura infatti non garantisce che il valore ottenuto sia compreso tra 0 e 1 in generale, perciò viene applicata un'operazione di minimo per cui, qualora il valore della funzione dovesse eccedere 1, il valore restituito è 1.\n",
    "Inoltre, sia per evitare che il valore restituito dalla standardizzazione sia negativo, sia perché ci interessa pesare la distanza dalla media e non tanto la distanza \"sinistra\" o \"destra\", al numeratore viene applicata un'operazione di valore assoluto.\n",
    "In questo modo ci siamo garantiti che il valore restituito sia sempre compreso tra 0 e 1, solo che a questo punto tanto più si avvicina a 0 tanto più si allinea alla distribuzione del traffico DDoS, avvicinandosi al valor medio della stessa, tanto più si avvicina a 1 quanto più se ne discosta.\n",
    "Per avere l'effetto contrario desiderato basta sottrarre da 1 il valore calcolato.\n",
    "\n",
    "A questo punto, tutti i pesi sono valori tra 0 e 1 e la loro media aritmetica può essere solamente un valore compreso tra 0 e 1, ottenendo il _range_ di valori desiderato."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0eeb005-31c5-4506-9a89-66a6dbf4e91f",
   "metadata": {},
   "source": [
    "### Valutazione delle prestazioni"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f95bc2-3517-406b-9dd2-19127d4a7934",
   "metadata": {},
   "source": [
    "In questa query, si sono volute valutare le prestazioni della funzione metrica così definita.\n",
    "Questo significa calcolare il numero di \"true positive\", \"false positive\", \"true negative\" e \"false negative\" prodotti dall'applicazione della metrica sul _dataset_ originale.\n",
    "Per \"true positive\" e \"false positive\" si intendono i _record_ associati correttamente alle classi di appartenenza che sono quella degli attacchi DDoS e del traffico legittimo.\n",
    "Invece, per \"false positive\" e \"false negative\" il viceversa, ovvero le istanze incorrettamente classificate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6432ca-9b47-4d6d-b842-9c47f893809e",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-26T11:20:01.372663Z",
     "iopub.status.idle": "2022-06-26T11:20:01.373143Z",
     "shell.execute_reply": "2022-06-26T11:20:01.372955Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "val flowDataDataset =\n",
    "    recordDataset.\n",
    "        filter(_.duration > 0.0).\n",
    "        map(r =>\n",
    "          (\n",
    "            (r.sourceAddress, r.sourcePort, r.destinationAddress, r.destinationPort, r.protocol),\n",
    "            (r.duration, r.packets, r.bytes),\n",
    "          ),\n",
    "        ).\n",
    "        reduceByKey { case ((duration1, packets1, bytes1), (duration2, packets2, bytes2)) =>\n",
    "          (duration1 + duration2, packets1 + packets2, bytes1 + bytes2)\n",
    "        }.\n",
    "        map { case (k, (duration, packets, bytes)) => (k, (packets / duration, bytes / duration)) }\n",
    "\n",
    "val metricDataset =\n",
    "    recordDataset.\n",
    "    map(r => (\n",
    "        (r.sourceAddress, r.sourcePort, r.destinationAddress, r.destinationPort, r.protocol),\n",
    "        (r.packets, r.bytes, r.rate, if (r.duration > 0.0) r.bytes / r.duration else 0.0, r.isDDoS)\n",
    "    )).\n",
    "    join(flowDataDataset).\n",
    "    map { \n",
    "        case(\n",
    "            (_, _, destinationAddress, destinationPort, _), \n",
    "            ((packets, bytes, rate, byteRate, isDDoS), (flowRate, flowByteRate))\n",
    "        ) => \n",
    "        (isDDoS, metric(destinationPort, destinationAddress, packets, bytes, rate, byteRate, flowRate, flowByteRate) >= 0.1)\n",
    "    }.\n",
    "    map { case(actual, predicted) => \n",
    "        if (actual == predicted) (if (actual) (1, 0) else (0, 1), (0, 0))\n",
    "        else ((0, 0), if (!actual) (1, 0) else (0, 1))\n",
    "    }.\n",
    "    reduce { case(((truePositive1, trueNegative1), (falsePositive1, falseNegative1)), ((truePositive2, trueNegative2), (falsePositive2, falseNegative2))) =>\n",
    "        ((truePositive1 + truePositive2, trueNegative1 + trueNegative2), (falsePositive1 + falsePositive2, falseNegative1 + falseNegative2))\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca71d58c-06ee-4c59-8eba-f4f7a708776b",
   "metadata": {},
   "source": [
    "La _query_ prende in input l'intero _dataset_ e un'aggregazione del _dataset_ che raggruppa i _flow_ in esso e produce in output una coppia di valori, ognuno dei quali è a sua volta una coppia, la prima sono i \"true positive\" e i \"true negative\", mentre la seconda è costituita dai \"false positive\" e dai \"false negative\".\n",
    "\n",
    "La _query_ prende in input un totale di 11.2 GB e completa in circa 4.8 minuti.\n",
    "\n",
    "La _query_ per prima cosa crea il _dataset_ aggregato rimuovendo i _record_ con durata inferiore a 0, che porterebbero a dei risultati erronei nei calcoli successivi.\n",
    "Dopodiché, trasforma ciascun _record_ in una coppia chiave-valore dove la chiave rappresenta l'identificatore di un flusso, quindi l'insieme dei valori indirizzo IP sorgente, porta sorgente, indirizzo IP destinazione, porta destinazione e protocollo di trasporto.\n",
    "Il valore è invece rappresentato dalle colonne che saranno necessarie in un secondo momento, cioè la durata, il numero di pacchetti e il numero di _byte_.\n",
    "Viene quindi effettuata una somma di questi valori per ciascun flusso e poi un'ultima trasformazione per ottenere dalle tre colonne i due valori di interesse, cioè il numero di pacchetti al secondo e il numero di _byte_ al secondo per flusso.\n",
    "\n",
    "La seconda parte della _query_ si preoccupa invece di trasformare il _dataset_ in modo che ogni _record_ sia nella forma chiave-valore.\n",
    "La chiave è la stessa che per il _dataset_ aggregato precedentemente, mentre il valore è una tupla fatta dalle colonne mancanti per il calcolo della metrica più quella che ci dice se il _record_ appartiene a traffico DDoS o meno.\n",
    "Il numero di _byte_ al secondo è forzato a 0 se la durata del _record_ stesso è 0, per semplicità.\n",
    "In seguito viene effettuato il _join_ tra i due _dataset_ e poi trasformata ogni riga per ottenere una coppia di valori dove il primo indica se la riga appartiene a traffico DDoS o meno, mentre la seconda è la predizione effettuata dalla metrica.\n",
    "Il valore di cut-off è stato manualmente impostato a 0.01 perché capace di dare le prestazioni migliori.\n",
    "\n",
    "A questo punto alla _query_ non resta altro da fare che trasformare la coppia di valori in uno dei quattro casi possibili di predizione, ovvero \"true positive\", \"true negative\", \"false positive\" e \"false negative\".\n",
    "Viene quindi costruita una coppia di coppie di valori che avrà il valore 1 in corrispondenza della posizione inerente allo specifico caso e infine verrà effettuata una somma dei valori di queste tuple così da poter ottenere il conteggio per ciascun caso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3555c6fc-a861-4f9f-a82a-007cfeaee893",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-26T11:20:01.374158Z",
     "iopub.status.idle": "2022-06-26T11:20:01.374602Z",
     "shell.execute_reply": "2022-06-26T11:20:01.374416Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "val flowBroadcast = sc.broadcast(flowDataDataset.collectAsMap())\n",
    "\n",
    "val metricDataset =\n",
    "    recordDataset.\n",
    "    map(r => (\n",
    "        (r.sourceAddress, r.sourcePort, r.destinationAddress, r.destinationPort, r.protocol),\n",
    "        (r.packets, r.bytes, r.rate, if (r.duration > 0.0) r.bytes / r.duration else 0.0, r.isDDoS)\n",
    "    )).\n",
    "    map {\n",
    "        case (k, v) => flowBroadcast.value.get(k).map(r => (k, (v, r)))\n",
    "    }.\n",
    "    filter(_.isDefined).\n",
    "    map(_.get).\n",
    "    map { \n",
    "        case(\n",
    "            (_, _, destinationAddress, destinationPort, _), \n",
    "            ((packets, bytes, rate, byteRate, isDDoS), (flowRate, flowByteRate))\n",
    "        ) => \n",
    "        (isDDoS, metric(destinationPort, destinationAddress, packets, bytes, rate, byteRate, flowRate, flowByteRate) >= 0.5)\n",
    "    }.\n",
    "    map { case(actual, predicted) => \n",
    "        if (actual == predicted) (if (actual) (1, 0) else (0, 1), (0, 0))\n",
    "        else ((0, 0), if (!actual) (1, 0) else (0, 1))\n",
    "    }.\n",
    "    reduce { case(((truePositive1, trueNegative1), (falsePositive1, falseNegative1)), ((truePositive2, trueNegative2), (falsePositive2, falseNegative2))) =>\n",
    "        ((truePositive1 + truePositive2, trueNegative1 + trueNegative2), (falsePositive1 + falsePositive2, falseNegative1 + falseNegative2))\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b79902-f8c2-4f9d-972e-fa069ee4ddef",
   "metadata": {},
   "source": [
    "Un primo tentativo di ottimizzazione ha coinvolto l'utilizzo delle _broadcast variables_.\n",
    "L'idea è stata quella di effettuare il _broadcast_ a tutti gli _executor_ del _dataset_ più piccolo, ovvero quello aggregato.\n",
    "Il tempo di esecuzione della _query_ si è ridotto a 1.5 minuti, di cui 27 secondi sono per effettuare la _collect_ del primo _dataset_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7209f53f-67c0-4eda-aeb7-b8186f511285",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-26T11:20:01.375603Z",
     "iopub.status.idle": "2022-06-26T11:20:01.375963Z",
     "shell.execute_reply": "2022-06-26T11:20:01.375789Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "val metricDataset =\n",
    "    recordDataset.\n",
    "    map(r => (\n",
    "        (r.sourceAddress, r.sourcePort, r.destinationAddress, r.destinationPort, r.protocol),\n",
    "        (r.packets, r.bytes, r.rate, if (r.duration > 0.0) r.bytes / r.duration else 0.0, r.isDDoS)\n",
    "    )).\n",
    "    partitionBy(new HashPartitioner(140)).\n",
    "    join(flowDataDataset).\n",
    "    map { \n",
    "        case(\n",
    "            (_, _, destinationAddress, destinationPort, _), \n",
    "            ((packets, bytes, rate, byteRate, isDDoS), (flowRate, flowByteRate))\n",
    "        ) => \n",
    "        (isDDoS, metric(destinationPort, destinationAddress, packets, bytes, rate, byteRate, flowRate, flowByteRate) >= 0.5)\n",
    "    }.\n",
    "    map { case(actual, predicted) => \n",
    "        if (actual == predicted) (if (actual) (1, 0) else (0, 1), (0, 0))\n",
    "        else ((0, 0), if (!actual) (1, 0) else (0, 1))\n",
    "    }.\n",
    "    reduce { case(((truePositive1, trueNegative1), (falsePositive1, falseNegative1)), ((truePositive2, trueNegative2), (falsePositive2, falseNegative2))) =>\n",
    "        ((truePositive1 + truePositive2, trueNegative1 + trueNegative2), (falsePositive1 + falsePositive2, falseNegative1 + falseNegative2))\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dea6ec3-81ad-43d0-8607-f680ca558f97",
   "metadata": {},
   "source": [
    "Una seconda tecnica di ottimizzazione testata è stata quella di introdurre un \"HashPartitioner\" capace di ridurre le partizioni prima dell'esecuzione della _join_.\n",
    "Il _partitioner_ è stato applicato sul _dataset_ più grande, in modo che fosse solo il più piccolo dei due a subire _shuffling_.\n",
    "Questa tecnica ha migliorato il tempo impiegato dalla _query_ portandolo ad 1.8 minuti, quando si dimezza il numero di partizioni a 140.\n",
    "Aumentare il numero di partizioni peggiora il tempo di esecuzione, così come diminuirlo rispetto a questo valore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb44464b-e7ab-4109-8fc6-c063acee514c",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-26T11:20:01.376956Z",
     "iopub.status.idle": "2022-06-26T11:20:01.377402Z",
     "shell.execute_reply": "2022-06-26T11:20:01.377215Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "val partitioner = new HashPartitioner(28)\n",
    "\n",
    "val flowDataDataset =\n",
    "    recordDataset.\n",
    "        filter(_.duration > 0.0).\n",
    "        map(r =>\n",
    "          (\n",
    "            (r.sourceAddress, r.sourcePort, r.destinationAddress, r.destinationPort, r.protocol),\n",
    "            (r.duration, r.packets, r.bytes),\n",
    "          ),\n",
    "        ).\n",
    "        reduceByKey { case ((duration1, packets1, bytes1), (duration2, packets2, bytes2)) =>\n",
    "          (duration1 + duration2, packets1 + packets2, bytes1 + bytes2)\n",
    "        }.\n",
    "        map { case (k, (duration, packets, bytes)) => (k, (packets / duration, bytes / duration)) }.\n",
    "        partitionBy(partitioner)\n",
    "\n",
    "val metricDataset =\n",
    "    recordDataset.\n",
    "    map(r => (\n",
    "        (r.sourceAddress, r.sourcePort, r.destinationAddress, r.destinationPort, r.protocol),\n",
    "        (r.packets, r.bytes, r.rate, if (r.duration > 0.0) r.bytes / r.duration else 0.0, r.isDDoS)\n",
    "    )).\n",
    "    partitionBy(partitioner).\n",
    "    join(flowDataDataset).\n",
    "    map { \n",
    "        case(\n",
    "            (_, _, destinationAddress, destinationPort, _), \n",
    "            ((packets, bytes, rate, byteRate, isDDoS), (flowRate, flowByteRate))\n",
    "        ) => \n",
    "        (isDDoS, metric(destinationPort, destinationAddress, packets, bytes, rate, byteRate, flowRate, flowByteRate) >= 0.5)\n",
    "    }.\n",
    "    map { case(actual, predicted) => \n",
    "        if (actual == predicted) (if (actual) (1, 0) else (0, 1), (0, 0))\n",
    "        else ((0, 0), if (!actual) (1, 0) else (0, 1))\n",
    "    }.\n",
    "    reduce { case(((truePositive1, trueNegative1), (falsePositive1, falseNegative1)), ((truePositive2, trueNegative2), (falsePositive2, falseNegative2))) =>\n",
    "        ((truePositive1 + truePositive2, trueNegative1 + trueNegative2), (falsePositive1 + falsePositive2, falseNegative1 + falseNegative2))\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839a669a-aad5-45b0-ba36-923ff33e5236",
   "metadata": {},
   "source": [
    "L'ultima tecnica di ottimizzazione impiegata è stata quella di applicare lo stesso _partitioner_ di tipo \"HashPartitioner\" su entrambi i _dataset_, così da fare lo _shuffling_ solamente all'inizio e la _join_ deve solamente occuparsi di accoppiare le partizioni nel modo giusto.\n",
    "Questa tecnica migliora le prestazioni della _query_, abbassando il tempo di esecuzione a 3.7 minuti utilizzando solamente 28 partizioni.\n",
    "Aumentarle ulteriormente non fa ridurre ulteriormente la durata della _query_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63a2e17-9b4e-408f-bdc6-3ff25da66a0f",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-26T11:20:01.378679Z",
     "iopub.status.idle": "2022-06-26T11:20:01.378928Z",
     "shell.execute_reply": "2022-06-26T11:20:01.378813Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "println(\"|                    | Actually positive | Actually negative |\")\n",
    "println(\"|--------------------|-------------------|-------------------|\")\n",
    "println(f\"| Predicted positive | ${metricDataset._1._1.toString}%-17s | ${metricDataset._2._1.toString}%-17s |\")\n",
    "println(f\"| Predicted negative | ${metricDataset._2._2.toString}%-17s | ${metricDataset._1._2.toString}%-17s |\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187e4c2f-75ef-4a23-b4cd-9bea9a7428d8",
   "metadata": {},
   "source": [
    "Come si può osservare, la metrica è molto buona nell'individuare i _record_ che appartengono a traffico legittimo, meno nel individuare gli attacchi DDoS, essendo perciò più conservativa.\n",
    "Gli errori che compie sono comunque relativamente bassi e così fatta non soffre di falsi positivi, segnalando traffico da bloccare che invece è legittimo.\n",
    "Certamente, risultati più veritieri si sarebbero ottenuti basandosi su di un _test set_ differente dal _training set_ utilizzato, che avrebbe evidenziato potenziali problemi di _overfitting_."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark",
   "language": "",
   "name": "sparkkernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
