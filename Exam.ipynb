{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4468a763-ee2d-4e4a-8eb1-1fd9e6dac8d8",
   "metadata": {},
   "source": [
    "# DDoS dataset analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060d8283-69b8-4a27-921c-bf3052e0daea",
   "metadata": {},
   "source": [
    "L'obiettivo di questo progetto è analizzare un _dataset_ contenente informazioni relative sia ad attacchi DDoS che a normale traffico.\n",
    "Questo per poter realizzare un'applicazione capace di distinguere il traffico sospetto da quello legittimo e poter quindi tempestivamente bloccare i tentativi di attacco."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031bc6ff-2d80-4ff3-a487-82dabbb6c93b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-17T09:34:21.907675Z",
     "iopub.status.busy": "2022-06-17T09:34:21.907419Z"
    },
    "tags": []
   },
   "source": [
    "## Descrizione del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e496dcb9",
   "metadata": {},
   "source": [
    "Il _dataset_ è stato tratto da un _paper_ realizzato dalla \"University of New South Wales\", in Australia.\n",
    "Il _paper_ è stato pubblicato su [Science Direct](https://www.sciencedirect.com/science/article/abs/pii/S0167739X18327687) ed è disponibile su [ResearchGate](https://www.researchgate.net/publication/328736466_Towards_the_Development_of_Realistic_Botnet_Dataset_in_the_Internet_of_Things_for_Network_Forensic_Analytics_Bot-IoT_Dataset) in _preprint_.\n",
    "Come è scritto nello stesso, l'obiettivo del _paper_ era la realizzazione del _dataset_ stesso, rispettando le condizioni di massimo realismo possibile del traffico generato e della configurazione dell'ambiente in cui gli attacchi simulati sono stati svolti.\n",
    "\n",
    "Il _paper_ indica anche il fatto che sono stati generate diverse tipologie di attacco, ma noi considereremo solamente quelle inerenti agli attacchi di tipo \"Distributed Denial of Service\", o \"DDoS\" in breve.\n",
    "Il _software_ utilizzato per effettuare le catture dei pacchetti è stato [Argus](https://openargus.org/), la cui documentazione, nonché i suoi [esempi d'uso](https://openargus.org/using-argus), indicano come sono costruiti i _record_ che l'applicazione salva nel momento nel quale viene fatta una cattura di rete.\n",
    "\n",
    "Ogni _record_ è il risultato di un raggruppamento di più pacchetti che svolgono la stessa funzione all'interno di una specifica connessione, o _flow_.\n",
    "Ad esempio, un _record_ può contenere i pacchetti utilizzati dal protocollo \"TCP\" per effettuare l'_handshake_ con un'altro nodo di rete, il corpo della trasmissione, oppure la chiusura finale.\n",
    "Per questo motivo ogni _record_, oltre a contenere informazioni capaci di identificare sorgente e destinazione della connessione, contengono anche dati derivanti dall'aggregazione sulle informazioni di più pacchetti.\n",
    "Infine, dacché è possibile risalire dai _record_ alle singole connessioni, così come esplicitato nel _paper_ stesso, sono presenti anche già informazioni di aggregazione su alcuni parametri tra più record, informazioni che ci aspettiamo siano replicate uguali tra tutti i _record_ coinvolti.\n",
    "\n",
    "Il sito in cui il _dataset_ è stato pubblicato è [questo](https://research.unsw.edu.au/projects/bot-iot-dataset), mentre il _download_ diretto dei file può essere fatto dalla [cartella](https://cloudstor.aarnet.edu.au/plus/s/umT99TnxvbpkkoE?path=%2FLabelling) di un servizio _cloud_ della UNSW.\n",
    "Purtroppo, non è possibile effettuare il _download_ diretto dei file.\n",
    "I _file_ che sono stati utilizzati in questo progetto sono quelli denominati \"DDoS_HTTP.csv\", \"DDoS_TCP.csv\" e \"DDoS_UDP.csv\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf05e9c-8bdf-4444-a221-fc4a00eebaf0",
   "metadata": {},
   "source": [
    "### Descrizione dei file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09614887-84fa-43db-84a7-a90dab519609",
   "metadata": {},
   "source": [
    "I tre _file_ che sono stati utilizzati contengono tre diverse sotto-categorie di attacchi, ovvero attacchi che inviano messaggi \"HTTP\", segmenti \"TCP\" e datagrammi \"UDP\".\n",
    "Non siamo interessati a tenere conto di questa distinzione, tanto più che tutti e tre i _file_ essendo stati generati dallo stesso _tool_, possiedono lo stesso formato, \"CSV\", e gli stessi campi.\n",
    "\n",
    "I campi presenti in ciascun file sono i seguenti:\n",
    "\n",
    "* \"stime\": la data e l'ora di ricezione del primo pacchetto del _record_\n",
    "* \"flgs\": le _flag_ dello stato della connessione presenti nei pacchetti del _record_\n",
    "* \"proto\": il protocollo di livello di rete utilizzato dai pacchetti del _record_\n",
    "* \"saddr\": l'indirizzo IP dell'interfaccia sorgente dei pacchetti del _record_\n",
    "* \"sport\": la porta dell'interfaccia sorgente dei pacchetti del _record_\n",
    "* \"dir\": la direzione del flusso dati, da sorgente a destinazione, viceversa o bidirezionale\n",
    "* \"daddr\": l'indirizzo IP dell'interfaccia destinazione dei pacchetti del _record_\n",
    "* \"dport\": la porta dell'interfaccia destinazione dei pacchetti del _record_\n",
    "* \"pkts\": il numero di pacchetti aggregati dal _record_\n",
    "* \"bytes\": la somma dei _byte_ dei pacchetti aggregati\n",
    "* \"state\": lo stato della connessione per i pacchetti aggregati dal _record_\n",
    "* \"srcid\": l'identificatore usato dal _tool_ \"Argus\" per identificare la sorgente dati\n",
    "* \"ltime\": la data e l'ora di ricezione dell'ultimo pacchetto del _record_\n",
    "* \"seq\": il numero di sequenza che il _tool_ \"Argus\" ha assegnato al _record_\n",
    "* \"dur\": la durata totale del _record_ \n",
    "* \"mean\": la durata media dei _record_ aggregati\n",
    "* \"stddev\": la deviazione standard dei _record_ aggregati\n",
    "* \"smac\": l'indirizzo MAC della sorgente dei pacchetti del _record_\n",
    "* \"dmac\": l'indirizzo MAC della destinazione dei pacchetti del _record_\n",
    "* \"sum\": la somma delle durate dei _record_ aggregati\n",
    "* \"min\": il minimo delle durate dei _record_ aggregati_\n",
    "* \"max\": il massimo delle durate dei _record_ aggregati\n",
    "* \"soui\": lo \"Organizationally Unique Identifier\" dell'indirizzo MAC della sorgente dei pacchetti del _record_\n",
    "* \"doui\": lo \"Organizationally Unique Identifier\" dell'indirizzo MAC della destinazione dei pacchetti del _record_\n",
    "* \"sco\": il \"Country Code\" associato all'indirizzo IP della sorgente dei pacchetti nel _record_\n",
    "* \"dco\": il \"Country Code\" associato all'indirizzo IP della destinazione dei pacchetti nel _record_\n",
    "* \"spkts\": il numero di pacchetti inviati dalla sorgente alla destinazione in questo _record_\n",
    "* \"dpkts\": il numero di pacchetti inviati dalla destinazione alla sorgente in questo _record_\n",
    "* \"sbytes\": il numero di _byte_ inviati dalla sorgente alla destinazione in questo _record_\n",
    "* \"dbytes\": il numero di _byte_ inviati dalla destinazione alla sorgente in questo _record_\n",
    "* \"rate\": i pacchetti al secondo inviati in questo _record_\n",
    "* \"srate\": i pacchetti al secondo inviati dalla sorgente alla destinazione in questo _record_\n",
    "* \"drate\": i pacchetti al secondo inviati dalla destinazione alla sorgente in questo _record_\n",
    "* \"record\": questa feature non è spiegata all'interno del _paper_ né tantomeno nella documentazione di \"Argus\"\n",
    "* \"attack: se il _record_ è parte di un attacco o meno\n",
    "* \"category\": la categoria dell'attacco\n",
    "* \"subcategory\": la specifica sotto-categoria dell'attacco\n",
    "\n",
    "I campi che abbiamo utilizzato nell'analisi sono stati:\n",
    "\n",
    "* stime\n",
    "* proto\n",
    "* saddr\n",
    "* sport\n",
    "* dir\n",
    "* daddr\n",
    "* dport\n",
    "* pkts\n",
    "* bytes\n",
    "* ltime\n",
    "* dur\n",
    "* spkts\n",
    "* dpkts\n",
    "* sbytes\n",
    "* dbytes\n",
    "* rate\n",
    "* srate\n",
    "* drate\n",
    "* attack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608d3d1a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Preparazione dei dati"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23733544",
   "metadata": {},
   "source": [
    "Per effettuare la preparazione dei dati, innanzitutto configuriamo il _kernel_ Spark che utilizzeremo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0bd4f15-fadb-4b4e-acc3-7d69545b82b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T14:14:32.068024Z",
     "iopub.status.busy": "2022-06-20T14:14:32.067795Z",
     "iopub.status.idle": "2022-06-20T14:14:32.085477Z",
     "shell.execute_reply": "2022-06-20T14:14:32.084930Z",
     "shell.execute_reply.started": "2022-06-20T14:14:32.067999Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'executorMemory': '8G', 'numExecutors': 3, 'executorCores': 3, 'conf': {'spark.dynamicAllocation.enabled': 'false'}, 'jars': ['s3a://unibo-bd2122-mcastellucci/project/evilplot-repl_2.12-0.8.1.jar', 's3a://unibo-bd2122-mcastellucci/project/evilplot_2.12-0.8.1.jar', 's3a://unibo-bd2122-mcastellucci/project/circe-core_2.12-0.13.0.jar', 's3a://unibo-bd2122-mcastellucci/project/circe-parser_2.12-0.13.0.jar', 's3a://unibo-bd2122-mcastellucci/project/circe-generic_2.12-0.13.0.jar', 's3a://unibo-bd2122-mcastellucci/project/circe-generic-extras_2.12-0.13.0.jar', 's3a://unibo-bd2122-mcastellucci/project/scalactic_2.12-3.0.8.jar'], 'proxyUser': 'assumed-role_voclabs_user1847188_matteo_castellucci3_studio_unibo_it', 'kind': 'spark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "No active sessions."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure -f\n",
    "{\n",
    "    \"executorMemory\": \"8G\", \n",
    "    \"numExecutors\": 3, \n",
    "    \"executorCores\": 3, \n",
    "    \"conf\": {\n",
    "        \"spark.dynamicAllocation.enabled\": \"false\"\n",
    "    }, \n",
    "    \"jars\": [\n",
    "        \"s3a://unibo-bd2122-mcastellucci/project/evilplot-repl_2.12-0.8.1.jar\",\n",
    "        \"s3a://unibo-bd2122-mcastellucci/project/evilplot_2.12-0.8.1.jar\",\n",
    "        \"s3a://unibo-bd2122-mcastellucci/project/circe-core_2.12-0.13.0.jar\",\n",
    "        \"s3a://unibo-bd2122-mcastellucci/project/circe-parser_2.12-0.13.0.jar\",\n",
    "        \"s3a://unibo-bd2122-mcastellucci/project/circe-generic_2.12-0.13.0.jar\",\n",
    "        \"s3a://unibo-bd2122-mcastellucci/project/circe-generic-extras_2.12-0.13.0.jar\",\n",
    "        \"s3a://unibo-bd2122-mcastellucci/project/scalactic_2.12-3.0.8.jar\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e6c9eb",
   "metadata": {},
   "source": [
    "Dopodiché, definiamo i percorsi dei file che utilizzeremo così come sono stati salvati sul servizio \"Amazon S3\" ed avviamo una nuova applicazione Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a0f0c12-591e-41de-a0b6-c76c7c035176",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T14:14:34.493585Z",
     "iopub.status.busy": "2022-06-20T14:14:34.493363Z",
     "iopub.status.idle": "2022-06-20T14:15:08.885211Z",
     "shell.execute_reply": "2022-06-20T14:15:08.884354Z",
     "shell.execute_reply.started": "2022-06-20T14:14:34.493560Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41f2a0d3dc1844f2a2f6699653f77474",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>10</td><td>application_1655730958384_0011</td><td>spark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-13-199.ec2.internal:20888/proxy/application_1655730958384_0011/\" class=\"emr-proxy-link\" emr-resource=\"j-1G8GZMGNSJCJ4\n",
       "\" application-id=\"application_1655730958384_0011\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-7-27.ec2.internal:8042/node/containerlogs/container_1655730958384_0011_01_000001/livy\" >Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bucketName: String = unibo-bd2122-mcastellucci/project\n",
      "pathTCPDataset: String = s3a://unibo-bd2122-mcastellucci/project/DDoS_TCP.csv\n",
      "pathUDPDataset: String = s3a://unibo-bd2122-mcastellucci/project/DDoS_UDP_original.csv\n",
      "pathHTTPDataset: String = s3a://unibo-bd2122-mcastellucci/project/DDoS_HTTP.csv\n",
      "res3: String = SPARK UI: Enable forwarding of port 20888 and connect to http://localhost:20888/proxy/application_1655730958384_0011/\n"
     ]
    }
   ],
   "source": [
    "val pathTCPDataset = s\"s3a://$bucketName/DDoS_TCP.csv\"\n",
    "val pathUDPDataset = s\"s3a://$bucketName/DDoS_UDP_original.csv\"\n",
    "val pathHTTPDataset = s\"s3a://$bucketName/DDoS_HTTP.csv\"\n",
    "\n",
    "\"SPARK UI: Enable forwarding of port 20888 and connect to http://localhost:20888/proxy/\" + sc.applicationId + \"/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6306a6ed",
   "metadata": {},
   "source": [
    "A questo punto è possibile costruire l'RDD per intero, in modo tale che contenga i dati di tutti e tre i file che ci interessano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9152666-1f46-4590-8465-3bb5413fbc15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T13:32:43.923965Z",
     "iopub.status.busy": "2022-06-20T13:32:43.923633Z",
     "iopub.status.idle": "2022-06-20T13:32:45.266239Z",
     "shell.execute_reply": "2022-06-20T13:32:45.265512Z",
     "shell.execute_reply.started": "2022-06-20T13:32:43.923929Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79b0cf1190f44346a340cc79ac71be50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: org.apache.spark.rdd.RDD[String] = s3a://unibo-bd2122-mcastellucci/project/DDoS_TCP.csv,s3a://unibo-bd2122-mcastellucci/project/DDoS_UDP_original.csv,s3a://unibo-bd2122-mcastellucci/project/DDoS_HTTP.csv MapPartitionsRDD[1] at textFile at <console>:31\n"
     ]
    }
   ],
   "source": [
    "val dataset = sc.textFile(s\"$pathTCPDataset,$pathUDPDataset,$pathHTTPDataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde7c25d",
   "metadata": {},
   "source": [
    "A questo punto si tratta di fare _parsing_ dei _record_ del _dataset_.\n",
    "Per effettuarlo correttamente, teniamo conto delle seguenti informazioni sui formati dei valori nelle singole colonne:\n",
    "\n",
    "* stime, ltime: il valore è un _timestamp_ in secondi dall'epoca UNIX, anche se è espresso in formato decimale per poter avere la precisione dei millisecondi\n",
    "* proto: il valore può essere uno tra \"tcp\", \"udp\", \"arp\" e \"icmp-v6\", ognuno dei quali è associato al corrispondente protocollo, sono però di interesse solamente i _record_ associati ai protocolli TCP e UDP\n",
    "* saddr, dadd: il valore è un indirizzo IP in formato \"dotted decimal notation\", può perciò essere salvato come String\n",
    "* sport, dport: il valore è un intero positivo che può arrivare ad un massimo di 65.536, perciò per poter essere rappresentato in linguaggio scala necessita di essere salvato in un Long\n",
    "* dir:\n",
    "* pkts, bytes, spkts, dpkts, sbytes, dbytes: il valore è un intero positivo di cui non è noto il massimo, per cui è logico pensare di salvare il valore in un Long\n",
    "* dur, rate, srate, drate: il valore è un numero decimale, perciò per mantenere la precisione massima utilizziamo un Double\n",
    "* attack: il valore può essere \"1\" nel caso il _record_ appartenga ad un attacco DDoS, \"0\" in caso contrario\n",
    "\n",
    "Detto questo, sono state implementati i seguenti Astract Data Types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cbcf5940-297d-434b-9329-84c68f592202",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T13:32:47.795028Z",
     "iopub.status.busy": "2022-06-20T13:32:47.794773Z",
     "iopub.status.idle": "2022-06-20T13:32:51.129667Z",
     "shell.execute_reply": "2022-06-20T13:32:51.129039Z",
     "shell.execute_reply.started": "2022-06-20T13:32:47.794984Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5e8cd69ee6745ac8cada2292cdfda44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import java.net.InetAddress\n",
      "import java.time.format.{DateTimeFormatter, DateTimeParseException}\n",
      "import java.time.{Instant, LocalDateTime, ZoneId}\n",
      "import scala.util.{Try, Success, Failure}\n",
      "import org.apache.spark.HashPartitioner\n",
      "defined object NetworkProtocol\n",
      "import NetworkProtocol.NetworkProtocol\n",
      "defined class Record\n",
      "defined object Record\n",
      "warning: previously defined class Record is not a companion to object Record.\n",
      "Companions must be defined together; you may wish to use :paste mode for this.\n"
     ]
    }
   ],
   "source": [
    "import java.net.InetAddress\n",
    "import java.time.format.{ DateTimeFormatter, DateTimeParseException }\n",
    "import java.time.{ Instant, LocalDateTime, ZoneId }\n",
    "import scala.util.{ Try, Success, Failure }\n",
    "import org.apache.spark.HashPartitioner\n",
    "\n",
    "object NetworkProtocol extends Enumeration {\n",
    "  type NetworkProtocol = Value\n",
    "\n",
    "  val TCP: NetworkProtocol = Value\n",
    "  val UDP: NetworkProtocol = Value\n",
    "}\n",
    "\n",
    "import NetworkProtocol.NetworkProtocol\n",
    "\n",
    "case class Record(\n",
    "    startTime: LocalDateTime,\n",
    "    protocol: NetworkProtocol,\n",
    "    sourceAddress: String,\n",
    "    sourcePort: Long,\n",
    "    direction: String,\n",
    "    destinationAddress: String,\n",
    "    destinationPort: Long,\n",
    "    packets: Long,\n",
    "    bytes: Long,\n",
    "    endTime: LocalDateTime,\n",
    "    duration: Double,\n",
    "    sourceBytes: Long,\n",
    "    destinationBytes: Long,\n",
    "    rate: Double,\n",
    "    sourceRate: Double,\n",
    "    destinationRate: Double,\n",
    "    isDDoS: Boolean\n",
    ")\n",
    "\n",
    "object Record {\n",
    "\n",
    "  def apply(r: Seq[String]): Option[Record] = \n",
    "    (for {\n",
    "      startTime <- Try(Instant.ofEpochMilli((r.head.toDouble * 1000).toLong).atZone(ZoneId.systemDefault()).toLocalDateTime)\n",
    "      protocol <- if (r(2) == \"tcp\") Success(NetworkProtocol.TCP) else if (r(2) == \"udp\") Success(NetworkProtocol.UDP) else Failure(new IllegalStateException())\n",
    "      sourceAddress = r(3)\n",
    "      sourcePort <- Try(r(4).toLong)\n",
    "      direction = r(5)\n",
    "      destinationAddress = r(6)\n",
    "      destinationPort <- Try(r(7).toLong)\n",
    "      packets <- Try(r(8).toLong)\n",
    "      bytes <- Try(r(9).toLong)\n",
    "      endTime <- Try(Instant.ofEpochMilli((r(12).toDouble * 1000).toLong).atZone(ZoneId.systemDefault()).toLocalDateTime)\n",
    "      duration <- Try(r(14).toDouble)\n",
    "      sourceBytes <- Try(r(28).toLong)\n",
    "      destinationBytes <- Try(r(29).toLong)\n",
    "      rate <- Try(r(30).toDouble)\n",
    "      sourceRate <- Try(r(31).toDouble)\n",
    "      destinationRate <- Try(r(32).toDouble)\n",
    "      isDDoS = r(34) == \"1\"\n",
    "     } yield new Record(\n",
    "         startTime,\n",
    "         protocol,\n",
    "         sourceAddress,\n",
    "         sourcePort,\n",
    "         direction,\n",
    "         destinationAddress,\n",
    "         destinationPort,\n",
    "         packets,\n",
    "         bytes,\n",
    "         endTime,\n",
    "         duration,\n",
    "         sourceBytes,\n",
    "         destinationBytes,\n",
    "         rate,\n",
    "         sourceRate,\n",
    "         destinationRate,\n",
    "         isDDoS\n",
    "       )\n",
    "    ).toOption\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac53ff3",
   "metadata": {},
   "source": [
    "Alla definizione è seguito il parsing vero e proprio, che ha tenuto conto del fatto che i tre _file_, essendo in formato CSV, hanno le virgolette che circondano ogni valore di ogni colonna e sono separati dai punti e virgola.\n",
    "Assieme ai _record_ \"legittimi\", per così dire, saranno presenti anche le intestazioni dei tre _file_.\n",
    "Questo però non ci preoccupa perché sappiamo che il _parser_ eliminerà correttamente quelle righe dall'RDD che caricheremo, non avendo lo stesso formato delle altre.\n",
    "Effettuiamo il _caching_ del _dataset_ perché lo riutilizzeremo più volte e così riusciamo a vedere la sua occupazione in formato non serializzato.\n",
    "La quantità di memoria occupata è di 8.1GB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "20bb05ff-f850-49fb-a432-c977b86f5ce6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T13:32:52.803848Z",
     "iopub.status.busy": "2022-06-20T13:32:52.803612Z",
     "iopub.status.idle": "2022-06-20T13:32:53.590087Z",
     "shell.execute_reply": "2022-06-20T13:32:53.589458Z",
     "shell.execute_reply.started": "2022-06-20T13:32:52.803824Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33821748fde748b0a49ffa17c09fd2e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recordDataset: org.apache.spark.rdd.RDD[Record] = MapPartitionsRDD[6] at map at <console>:41\n"
     ]
    }
   ],
   "source": [
    "val recordDataset = \n",
    "    dataset.\n",
    "        map(_.replace(\"\\\"\", \"\")).\n",
    "        map(_.split(\";\")).\n",
    "        map(Record(_)).\n",
    "        filter(_.isDefined).\n",
    "        map(_.get).\n",
    "        cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6564fd",
   "metadata": {},
   "source": [
    "Il dataset così caricato e ripulito è formato da 38.532.503 _record_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66703bfe-d891-4e3b-af72-a99026509a0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T13:32:55.653517Z",
     "iopub.status.busy": "2022-06-20T13:32:55.653251Z",
     "iopub.status.idle": "2022-06-20T13:35:29.495074Z",
     "shell.execute_reply": "2022-06-20T13:35:29.494420Z",
     "shell.execute_reply.started": "2022-06-20T13:32:55.653490Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "072f79cf736d416c8344cc3837d50081",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recordDatasetSize: Long = 38532503\n"
     ]
    }
   ],
   "source": [
    "val recordDatasetSize = recordDataset.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5854d3ed-038e-4f2d-9bb5-dd11abd93e93",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013d6e46-2423-4105-aa1a-7b83b9cb7f0c",
   "metadata": {},
   "source": [
    "### Percentuale di _record_ associati ad attacchi DDoS nell'intero _dataset_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f103adac-357a-40f7-ba04-b23952fa3e22",
   "metadata": {},
   "source": [
    "Con questa query si vuole calcolare la percentuale di _record_ che appartengono ad attacchi DDoS nel _dataset_ e così derivare anche il numero di _record_ che __non__ appartengono ad attacchi DDoS, ma a traffico legittimo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df3422b1-8b67-493f-8e9b-c302adf2dfe1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T13:35:31.689479Z",
     "iopub.status.busy": "2022-06-20T13:35:31.689208Z",
     "iopub.status.idle": "2022-06-20T13:36:27.173462Z",
     "shell.execute_reply": "2022-06-20T13:36:27.172841Z",
     "shell.execute_reply.started": "2022-06-20T13:35:31.689451Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c61d36f8736454799de780fba0b4507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ddosCount: (Int, Int) = (38531238,1265)\n"
     ]
    }
   ],
   "source": [
    "val ddosCount = \n",
    "    recordDataset.\n",
    "        map(r => if (r.isDDoS) (1, 0) else (0, 1)).\n",
    "        reduce{ case((ddosCount1, legitCount1), (ddosCount2, legitCount2)) => (ddosCount1 + ddosCount2, legitCount1 + legitCount2) }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cf014d-425d-49df-8c5e-6d65a3bac9b4",
   "metadata": {},
   "source": [
    "La query prende in input l'intero _dataset_ e produce due Long: il primo è il numero di _record_ appartenenti ad attacchi DDoS, il secondo è il numero di _record_ appartenenti a traffico legittimo.\n",
    "\n",
    "La query ha completato in media con un tempo di 52 secondi prendendo in input 12.7 GB di dati.\n",
    "\n",
    "L'implementazione scelta non fa altro che trasformare ogni _record_ in una coppia di valori, dove il primo rappresenta il conteggio dei _record_ associati ad attacchi, il secondo a traffico legittimo, che avrà il valore 1 nella posizione corrispondente a quale tipo di traffico il _record_ stesso appartiene, il valore 0 nell'altra.\n",
    "Dopodiché, viene compiuta un'operazione di _reduce_ che somma i valori nelle corrispondenti posizioni.\n",
    "\n",
    "È stata tentata una variante ottimizzata dove si raggruppavano i _record_ per tipologia di traffico di appartenenza, ma aveva un tempo di esecuzione comparabile a questa implementazione, pur raddoppiando il numero di _task_, dopodiché sulla nuova implementazione si è tentato di forzare il partizionamento a 2 partizioni tramite `HashPartioner`, ma ha peggiorato il tempo di esecuzione.\n",
    "Evidentemente lo _shuffling_ derivato dal ripartizionamento non è giustificato da un eventuale riduzione del tempo di esecuzione della _reduce_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c79a6a2-c423-477a-a19d-2406fbb64f4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T13:36:31.515187Z",
     "iopub.status.busy": "2022-06-20T13:36:31.514962Z",
     "iopub.status.idle": "2022-06-20T13:36:32.316053Z",
     "shell.execute_reply": "2022-06-20T13:36:32.315415Z",
     "shell.execute_reply.started": "2022-06-20T13:36:31.515163Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cde24f1f14a4f0c85f0ab4aa49ad238",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ddosPercentage: Double = 99.99671705728538\n",
      "legitPercentage: Double = 0.0032829427146219906\n"
     ]
    }
   ],
   "source": [
    "val ddosPercentage = ddosCount._1 / recordDatasetSize.toDouble * 100\n",
    "val legitPercentage = ddosCount._2 / recordDatasetSize.toDouble * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2c30a7-6f24-41ee-b69a-e49db468bbae",
   "metadata": {},
   "source": [
    "### Conteggio dei flussi catturati nel dataset\n",
    "Un flusso lo si identifica da (sourceIp, sourcePort, destinationIp, destinationPort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51ed9e1-e2f2-46b4-8966-3fb95c0a1504",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val flowsDataset = recordDataset.\n",
    "    groupBy(r => (r.saddr, r.sport, r.daddr, r.dport)).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7972a4c-ed76-463d-815e-0d1b61a3f76e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val flowsCount = flowsDataset.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821b1199-2f83-4a7e-8c75-3439bc4c9705",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val ddosFlowsCount = flowsDataset.filter { case (_, packets) => packets.forall(_.isDDoS) }.count()\n",
    "val legitFlowsCount = flowsDataset.filter { case (_, packets) => packets.forall(!_.isDDoS) }.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886b23bb-c752-46a8-affa-c0dce6a7cf98",
   "metadata": {},
   "source": [
    "Determinati i flussi, possiamo calcolare mediamente quanti pacchetti sono scambiati per ogni flusso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8701d7-a4a6-43c9-bcfc-c77fe44a6080",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val meanPacketPerFlow = datasetSize / flowsCount.toDouble\n",
    "val meanPacketDDoSFlow = ddosVolume / ddosFlowsCount.toDouble\n",
    "val meanPacketLegitFlow = legitVolume / legitFlowsCount.toDouble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d32695-b1c2-42cf-b689-3d6f7be58ca9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark",
   "language": "",
   "name": "sparkkernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
